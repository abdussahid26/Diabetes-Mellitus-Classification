{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1343052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f27b95-46b7-4eec-92a5-8f0b9fa8e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('Datasets/X_Train With Yeo Johnson 70-30.csv')\n",
    "\n",
    "x_test = pd.read_csv('Datasets/X_Test With Yeo Johnson 70-30.csv')\n",
    "\n",
    "y_train = pd.read_csv('Datasets/Y_Train With Yeo Johnson 70-30.csv')\n",
    "\n",
    "y_test = pd.read_csv('Datasets/Y_Test With Yeo Johnson 70-30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7226c2-5bd2-40dc-aee5-a5266c5eb101",
   "metadata": {},
   "source": [
    "# Dimentionality Reduction Using Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46ca636-9cf6-46ab-857b-74393e635ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 8)\n",
    " \n",
    "#apply PCA to transform the features to 2\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "\n",
    "X = X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737a8b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.420294</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.462838</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.550676</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.276193</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.273649</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.576403</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.530405</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.504353</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.408784</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.744521</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.240168</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.658784</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.588412</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.216151</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.408784</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.648454</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.334459</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender      AGE      Urea     Cr     HbA1c      Chol        TG     HDL  \\\n",
       "0       1.0  0.59375  0.420294  0.445  0.462838  0.375000  0.727273  0.7500   \n",
       "1       1.0  0.59375  1.000000  1.000  0.550676  0.781250  0.525253  0.5000   \n",
       "2       0.0  0.00000  0.276193  0.395  0.273649  0.484375  0.444444  0.6250   \n",
       "3       1.0  0.40625  0.576403  0.455  0.530405  0.578125  0.444444  0.5000   \n",
       "4       0.0  0.62500  0.504353  0.445  0.408784  0.281250  0.303030  0.5000   \n",
       "..      ...      ...       ...    ...       ...       ...       ...     ...   \n",
       "821     1.0  0.37500  0.744521  0.625  0.638514  0.515625  1.000000  0.8125   \n",
       "822     0.0  0.46875  0.240168  0.245  0.658784  0.625000  0.545455  0.5000   \n",
       "823     0.0  0.34375  0.588412  0.415  0.239865  0.250000  0.101010  0.5625   \n",
       "824     0.0  0.09375  0.216151  0.415  0.408784  0.562500  0.505051  1.0000   \n",
       "825     1.0  0.06250  0.648454  0.515  0.334459  0.484375  1.000000  0.3750   \n",
       "\n",
       "          LDL      VLDL       BMI  Class  \n",
       "0    0.203704  0.500000  0.367347      2  \n",
       "1    0.740741  0.461538  0.571429      2  \n",
       "2    0.388889  0.384615  0.040816      0  \n",
       "3    0.370370  0.384615  0.408163      2  \n",
       "4    0.277778  0.269231  0.285714      2  \n",
       "..        ...       ...       ...    ...  \n",
       "821  0.055556  1.000000  0.734694      2  \n",
       "822  0.722222  0.500000  0.816327      2  \n",
       "823  0.259259  0.076923  0.163265      0  \n",
       "824  0.185185  0.307692  0.204082      2  \n",
       "825  0.259259  0.884615  0.081633      1  \n",
       "\n",
       "[826 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff5b5c6-bd47-418a-be11-96bde3aca546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    690\n",
      "0     96\n",
      "1     40\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b66f30",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd33ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# X = data.drop(['Class'], axis = 1)\n",
    "#X = data.drop([0], axis = 1) # if only this attribute we drop from the dataset accuracy will rise to 100%\n",
    "# Y = data['Class']\n",
    "\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2,random_state = 0) # 80% training and 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 109) # 80% training and 20% test\n",
    "\n",
    "\n",
    "\n",
    "# x_train_smt = train_data.drop(['Class'], axis = 1)\n",
    "# y_train_smt = train_data['Class']\n",
    "\n",
    "# x_test_smt = test_data.drop(['Class'], axis = 1)\n",
    "# y_test_smt = test_data['Class']\n",
    "\n",
    "# print(XX.shape)\n",
    "# print(YY.shape)\n",
    "\n",
    "# # Fitting all data as training and testing.\n",
    "# x_train_smt, y_train_smt = (XX, YY)\n",
    "# x_test_smt, y_test_smt = (xx, yy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# both train_size and test_size are defined when we do not want to\n",
    "# use all the data for training and testing e.g. in below example we can\n",
    "# use train_size=0.4 and test_size=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c210ab6d-8168-45b3-aeea-5e919b883417",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cohen Kappa\", \"AUC\"]\n",
    "\n",
    "performance_dict = {}\n",
    "performance_dict['Metrics'] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3a14ab-2cf6-49f5-97ea-3d4de55e4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_grid = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cohen Kappa\", \"AUC\"]\n",
    "\n",
    "performance_dict_grid = {}\n",
    "performance_dict_grid['Metrics'] = metrics_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084133c",
   "metadata": {},
   "source": [
    "# SMOTETomek Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818e0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from collections import Counter\n",
    "# from imblearn.combine import SMOTETomek\n",
    "# counter = Counter(y_train)\n",
    "# print('Before', counter)\n",
    "# smtt = SMOTETomek(random_state = 139)\n",
    "# x_train_smt, y_train_smt = smtt.fit_resample(x_train, y_train)\n",
    "# counter = Counter(y_train_smt)\n",
    "# print('After', counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4e1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from collections import Counter\n",
    "# from imblearn.combine import SMOTETomek\n",
    "# counter = Counter(y_test)\n",
    "# print('Before', counter)\n",
    "# smtt = SMOTETomek(random_state = 139)\n",
    "# x_test_smt, y_test_smt = smtt.fit_resample(x_test, y_test)\n",
    "# counter = Counter(y_test_smt)\n",
    "# print('After', counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef41cb",
   "metadata": {},
   "source": [
    "# Support Vector Classifier Train, Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b42ba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216867469879518\n",
      "[[ 22   0   3]\n",
      " [  3   0   5]\n",
      " [  2   0 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85        25\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.94      0.98      0.96       133\n",
      "\n",
      "    accuracy                           0.92       166\n",
      "   macro avg       0.59      0.62      0.60       166\n",
      "weighted avg       0.88      0.92      0.90       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "modelSVC = SVC(probability=True)\n",
    "modelSVC.fit(x_train, y_train)\n",
    "#modelSVC.fit(x_test, y_test)\n",
    "#print(modelSVC.score(x_test, y_test))\n",
    "\n",
    "y_pred_svc = modelSVC.predict(x_test)\n",
    "#y_pred = modelSVC.predict(x_train)\n",
    "svc_acc = accuracy_score(y_test, y_pred_svc)\n",
    "#ac = accuracy_score(y_train, y_pred)\n",
    "print(svc_acc)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9da7b475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.8778053862131179\n",
      "f1 Score  0.8991815679005617\n",
      "Recall  0.9216867469879518\n",
      "Specificity/TNR: 1.0\n",
      "Cohen Kappa: 0.7429116035263283\n",
      "AUC Score  0.9482794383636376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\2519269152.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "  PPV = TP/float(TP+FP)\n",
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\2519269152.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  FDR = FP/float(TP+FP)\n",
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\2519269152.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  MCC_SVC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "cmSVC = confusion_matrix(y_test, modelSVC.predict(x_test))\n",
    "\n",
    "#If we use TP TN FP and FN of below's comment we get range\n",
    "#FP = cmSVC.sum(axis=0) - np.diag(cmSVC)  \n",
    "#FN = cmSVC.sum(axis=1) - np.diag(cmSVC)\n",
    "#TP = np.diag(cmSVC)\n",
    "#TN = cmSVC.sum() - (FP + FN + TP)\n",
    "\n",
    "TP = cmSVC[1,1]  \n",
    "TN = cmSVC[0,0] \n",
    "FP = cmSVC[0,1] \n",
    "FN = cmSVC[1,0] \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/float(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/float(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/float(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/float(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/float(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/float(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/float(TP+FP)\n",
    "totalSVC=sum(sum(cmSVC))\n",
    "Accuracy = (TN+TP)/totalSVC\n",
    "# MCC\n",
    "val = (TP * TN) - (FP * FN)\n",
    "MCC_SVC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "\n",
    "\n",
    "Y_pred_svc = modelSVC.predict(x_test)\n",
    "\n",
    "\n",
    "cohen_score = cohen_kappa_score(y_test, Y_pred_svc)\n",
    "f1 = f1_score(y_test, Y_pred_svc, average = \"weighted\")\n",
    "precision = precision_score(y_test, Y_pred_svc, average = \"weighted\")\n",
    "recall = recall_score(y_test, Y_pred_svc, average = \"weighted\")\n",
    "\n",
    "pred_prob = modelSVC.predict_proba(x_test)\n",
    "auc_score = roc_auc_score(y_test, pred_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"Precision  {precision}\")\n",
    "print(f\"f1 Score  {f1}\")\n",
    "print(f\"Recall  {recall}\")\n",
    "specificity = TNR\n",
    "print(\"Specificity/TNR: \" + str(TNR))\n",
    "print(\"Cohen Kappa: \" + str(cohen_score))\n",
    "print(f\"AUC Score  {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68057915-0664-4af3-8dd8-cda50fcf3931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metrics': ['Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Cohen Kappa',\n",
       "  'AUC'],\n",
       " 'SVC': [0.9216867469879518,\n",
       "  0.8778053862131179,\n",
       "  0.9216867469879518,\n",
       "  0.8991815679005617,\n",
       "  0.7429116035263283,\n",
       "  0.9482794383636376]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_performances = [svc_acc, precision, recall, f1, cohen_score, auc_score ]\n",
    "performance_dict['SVC'] = svc_performances\n",
    "\n",
    "performance_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9f062",
   "metadata": {},
   "source": [
    "# Supper Vector Classifier Hyperparameter Tuning GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "720c869b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.07290735, 0.0413939 , 0.04967051, 0.0596375 , 0.08586488,\n",
       "        0.04637527, 0.05884166, 0.09295559, 0.11668735, 0.04169276,\n",
       "        0.04458327, 0.06842499, 0.07370207, 0.03850148, 0.03789797,\n",
       "        0.06023364, 0.07160761, 0.03847897, 0.03879604, 0.05535102,\n",
       "        0.06652162, 0.03770435, 0.05235679, 0.06213188, 0.07858603,\n",
       "        0.03720202, 0.04736907, 0.06482303, 0.07799127, 0.0384001 ,\n",
       "        0.04049516, 0.06352668, 0.11150091, 0.05186031, 0.0624402 ,\n",
       "        0.07260437, 0.07530742, 0.03919261, 0.04149125, 0.05534861,\n",
       "        0.15072029, 0.04048603, 0.04976416, 0.05156648, 0.16265893,\n",
       "        0.04019172, 0.04159114, 0.06352639, 0.17632494, 0.03959396,\n",
       "        0.03660131, 0.06113296, 0.18739517, 0.0440809 , 0.05275688,\n",
       "        0.07440057, 0.16785069, 0.03759594, 0.03769813, 0.05485573,\n",
       "        0.13763168, 0.03989315, 0.04846971, 0.04876888, 0.15727854,\n",
       "        0.04158905, 0.04298959, 0.06083395, 0.1787266 , 0.03929648,\n",
       "        0.03819737, 0.06283133, 0.19667044, 0.06143448, 0.06303127,\n",
       "        0.07190485, 0.22050619, 0.04228876, 0.04338248, 0.0595427 ,\n",
       "        0.14122379, 0.0415905 , 0.04817224, 0.09524207, 0.20475166,\n",
       "        0.04797428, 0.04288144, 0.06253445, 0.18531129, 0.04846826,\n",
       "        0.04906838, 0.09514542, 0.20156057, 0.04457529, 0.04228914,\n",
       "        0.06152909, 0.18640368, 0.04288559, 0.0369035 , 0.06572137,\n",
       "        0.14959729, 0.07160742, 0.0541537 , 0.06761856, 0.15548575,\n",
       "        0.04288707, 0.04578116, 0.05844605, 0.19407554, 0.04737308,\n",
       "        0.03820143, 0.07330313, 0.1809104 , 0.04019198, 0.03939407,\n",
       "        0.05924177, 0.16755579, 0.04099247, 0.03570094, 0.05445576,\n",
       "        0.13204339, 0.04168761, 0.05325611, 0.09005926, 0.2020612 ,\n",
       "        0.04528511, 0.04956732, 0.09484544, 0.21911259, 0.0424896 ,\n",
       "        0.03760154, 0.06123531, 0.19428244, 0.08387527, 0.04737215,\n",
       "        0.1027256 , 0.22340243, 0.05105987, 0.04209199, 0.06343219,\n",
       "        0.14161582, 0.04616554, 0.05135469, 0.06981292, 0.17702601,\n",
       "        0.0541549 , 0.04956789, 0.06113915, 0.22259836, 0.04787965,\n",
       "        0.04129131, 0.06672118, 0.18570232, 0.04318361, 0.03939588,\n",
       "        0.05943544, 0.17054269, 0.04288645, 0.03979032, 0.06033752,\n",
       "        0.13414123, 0.05146093, 0.05724823, 0.06083617, 0.15348661,\n",
       "        0.04308524, 0.04238825, 0.05644858, 0.17812459, 0.04198599,\n",
       "        0.03710241, 0.0611356 , 0.17662721, 0.04218562, 0.0385962 ,\n",
       "        0.05894144, 0.17064493, 0.04208682, 0.03540468, 0.05644829,\n",
       "        0.13483679, 0.06123497, 0.06961348, 0.05624838, 0.14151766,\n",
       "        0.0439791 , 0.04418104, 0.05604942, 0.17692845, 0.04438393,\n",
       "        0.03610492, 0.06263189, 0.17732816, 0.04438131, 0.03919401,\n",
       "        0.05993938, 0.16873214, 0.04328613, 0.03739953, 0.05664778,\n",
       "        0.13503816, 0.05216088, 0.05963988, 0.05834384, 0.13583648,\n",
       "        0.04318495, 0.04398158, 0.05635607, 0.17582653, 0.04448879,\n",
       "        0.03759332, 0.06243165, 0.17642252, 0.04397936, 0.04108922,\n",
       "        0.06004105, 0.17044339, 0.04408669, 0.03670316, 0.05884128,\n",
       "        0.13823028, 0.05864213, 0.07639613, 0.06841638, 0.13663361,\n",
       "        0.04498003, 0.04318359, 0.05495493, 0.1773252 , 0.04608195,\n",
       "        0.04597659, 0.06801915, 0.18610485, 0.05156446, 0.04118505,\n",
       "        0.0618345 , 0.1802139 , 0.04817343, 0.04128654, 0.05863872,\n",
       "        0.16495802, 0.07180619, 0.10481875, 0.051262  , 0.13753405,\n",
       "        0.04438167, 0.05395381, 0.0639257 , 0.17722871, 0.04448278,\n",
       "        0.03699756, 0.06332998, 0.17952385, 0.04377894, 0.04168727,\n",
       "        0.0594398 , 0.17243745, 0.04856699, 0.04527822, 0.06243255,\n",
       "        0.14661057, 0.04488502, 0.05166342, 0.04308617, 0.13274157,\n",
       "        0.04926968, 0.04497666, 0.05665088, 0.17453048, 0.04587786,\n",
       "        0.03889537, 0.06243246, 0.176228  , 0.04497981, 0.0393944 ,\n",
       "        0.06113265, 0.17455318, 0.05395465, 0.04667397, 0.07639511,\n",
       "        0.1402246 , 0.04826994, 0.05285513, 0.04418125, 0.13264232,\n",
       "        0.04527941, 0.04467974, 0.05425928, 0.17433081, 0.04568381,\n",
       "        0.03589818, 0.06223264, 0.17752435, 0.04508336, 0.03939342,\n",
       "        0.06034095, 0.17363522, 0.05754409, 0.04348378, 0.07629488,\n",
       "        0.13613935, 0.04716885, 0.05454865, 0.04388189, 0.13414056,\n",
       "        0.04597473, 0.04498174, 0.05394943, 0.17263741, 0.04568083,\n",
       "        0.04936719, 0.07031126, 0.19537675, 0.05086133, 0.0426908 ,\n",
       "        0.06093366, 0.18440652, 0.06113541, 0.04986606, 0.0669199 ,\n",
       "        0.13084416, 0.0472729 , 0.05395608, 0.0419893 , 0.13025002,\n",
       "        0.04598055, 0.04637742, 0.05475407, 0.17972109, 0.05505173,\n",
       "        0.03919497, 0.06432707, 0.18699553, 0.04657543, 0.04487655,\n",
       "        0.06662095, 0.18889384, 0.05485249, 0.04547987, 0.05804629,\n",
       "        0.12905548, 0.04637635, 0.05296335, 0.04308462, 0.13005681,\n",
       "        0.0456759 , 0.04358492, 0.05355666, 0.16794765, 0.04647572,\n",
       "        0.03580596, 0.06233044, 0.17722285, 0.04697714, 0.04068835,\n",
       "        0.06123178, 0.21173337, 0.07858968, 0.06073949, 0.07380023,\n",
       "        0.14511073, 0.04727821, 0.05406187, 0.04268007, 0.13015389,\n",
       "        0.04757605, 0.04468186, 0.05425386, 0.16864839, 0.04847198,\n",
       "        0.03680129, 0.06402566, 0.17762976, 0.04886856, 0.042084  ,\n",
       "        0.07858894, 0.20036621, 0.04647477, 0.03630252, 0.05774474,\n",
       "        0.1311518 , 0.04777243, 0.05904143, 0.04886818, 0.12975409,\n",
       "        0.04647152, 0.04477656, 0.05295742, 0.16854613, 0.04667237,\n",
       "        0.03720005, 0.06193771, 0.1771307 , 0.04767528, 0.04069312,\n",
       "        0.07369938, 0.187797  , 0.04707937, 0.03630419, 0.05774267]),\n",
       " 'std_fit_time': array([0.00993704, 0.0034616 , 0.00259425, 0.00364214, 0.00781605,\n",
       "        0.00885641, 0.01141308, 0.01199903, 0.01993396, 0.00987302,\n",
       "        0.00546248, 0.01038322, 0.00359997, 0.00119894, 0.00140163,\n",
       "        0.00597218, 0.00465066, 0.0017803 , 0.00211219, 0.00174336,\n",
       "        0.00270896, 0.00183389, 0.00744695, 0.00850588, 0.00442562,\n",
       "        0.00148838, 0.00631205, 0.00263794, 0.00351224, 0.00110796,\n",
       "        0.00299573, 0.00200315, 0.019502  , 0.00824922, 0.00763284,\n",
       "        0.01477621, 0.00479091, 0.00231778, 0.00391958, 0.00148313,\n",
       "        0.00720253, 0.00351349, 0.00229779, 0.00184138, 0.00326207,\n",
       "        0.00282293, 0.00240999, 0.00218444, 0.00350848, 0.00421099,\n",
       "        0.00189508, 0.00126024, 0.01260859, 0.00454362, 0.00587369,\n",
       "        0.00894651, 0.00312194, 0.00244451, 0.00159574, 0.00154879,\n",
       "        0.003789  , 0.00255821, 0.00343024, 0.00137134, 0.00938764,\n",
       "        0.00605024, 0.00191143, 0.00296024, 0.00478636, 0.00249065,\n",
       "        0.00292805, 0.00384475, 0.01667279, 0.00838327, 0.00724454,\n",
       "        0.01061906, 0.03325359, 0.00478643, 0.00363318, 0.00362341,\n",
       "        0.00648213, 0.00357574, 0.00161463, 0.02975417, 0.023364  ,\n",
       "        0.00932565, 0.00223028, 0.00274556, 0.00666389, 0.00632735,\n",
       "        0.00874876, 0.00904388, 0.01360511, 0.00345279, 0.00477964,\n",
       "        0.00367269, 0.01495618, 0.00184073, 0.00141119, 0.01326521,\n",
       "        0.02321153, 0.03200756, 0.0105625 , 0.00769685, 0.00820234,\n",
       "        0.00389094, 0.0030823 , 0.00149068, 0.00786811, 0.00418959,\n",
       "        0.00299486, 0.0075179 , 0.0055669 , 0.00167195, 0.00149261,\n",
       "        0.00081152, 0.00099815, 0.0023723 , 0.00131486, 0.00091819,\n",
       "        0.00482049, 0.00177149, 0.00701081, 0.03184749, 0.02350757,\n",
       "        0.00214475, 0.0079582 , 0.01549201, 0.01633485, 0.00196243,\n",
       "        0.00195673, 0.00200505, 0.03398345, 0.02543739, 0.00672397,\n",
       "        0.02808252, 0.02796024, 0.00869191, 0.00736244, 0.00808545,\n",
       "        0.00752222, 0.00209251, 0.00605667, 0.01236328, 0.01577681,\n",
       "        0.0166164 , 0.00637469, 0.00322835, 0.06048857, 0.00325456,\n",
       "        0.00442092, 0.00245405, 0.00741977, 0.00333843, 0.00135423,\n",
       "        0.00156296, 0.00653884, 0.00267505, 0.00287343, 0.00411653,\n",
       "        0.00827555, 0.00379039, 0.00289911, 0.01083309, 0.01706306,\n",
       "        0.00255218, 0.001202  , 0.00110137, 0.0055227 , 0.00211925,\n",
       "        0.0014673 , 0.00154326, 0.00437981, 0.00240919, 0.00126501,\n",
       "        0.00122405, 0.00397202, 0.00165697, 0.00067678, 0.0022826 ,\n",
       "        0.01140411, 0.00867418, 0.0108682 , 0.00414155, 0.00966582,\n",
       "        0.00261929, 0.00354202, 0.00207763, 0.00245101, 0.00309144,\n",
       "        0.00097214, 0.00177576, 0.00351277, 0.00303324, 0.001484  ,\n",
       "        0.00144231, 0.00229002, 0.00180195, 0.00316556, 0.00213286,\n",
       "        0.00912231, 0.00510736, 0.00709138, 0.00593907, 0.00350474,\n",
       "        0.00354447, 0.00229398, 0.00441752, 0.00275155, 0.0039357 ,\n",
       "        0.00454339, 0.00325399, 0.00220314, 0.002121  , 0.00226558,\n",
       "        0.00177731, 0.00210531, 0.00123895, 0.00225969, 0.0053317 ,\n",
       "        0.01448851, 0.00983008, 0.0132497 , 0.00766324, 0.00477623,\n",
       "        0.00276468, 0.00100249, 0.0022571 , 0.00408473, 0.00388567,\n",
       "        0.007627  , 0.00422312, 0.00966688, 0.00544148, 0.00305824,\n",
       "        0.00231705, 0.01715495, 0.00519903, 0.00520885, 0.00456805,\n",
       "        0.00975297, 0.02274734, 0.00863174, 0.00863839, 0.00587127,\n",
       "        0.00200786, 0.0084315 , 0.00942533, 0.00556959, 0.00142229,\n",
       "        0.0013011 , 0.00264087, 0.00173641, 0.00186673, 0.00339099,\n",
       "        0.00101962, 0.00229341, 0.00649498, 0.00590385, 0.00384195,\n",
       "        0.01506824, 0.00260614, 0.00187937, 0.00188582, 0.0037447 ,\n",
       "        0.00584369, 0.0018106 , 0.00716436, 0.00218578, 0.00141211,\n",
       "        0.00617982, 0.0036015 , 0.00342263, 0.00205706, 0.0011174 ,\n",
       "        0.00399275, 0.00432819, 0.01006716, 0.00750029, 0.01271941,\n",
       "        0.01130409, 0.00210157, 0.00316214, 0.00271041, 0.00383317,\n",
       "        0.00195051, 0.00177208, 0.00219701, 0.00410278, 0.00183146,\n",
       "        0.00076934, 0.00219099, 0.0041555 , 0.00147421, 0.00278717,\n",
       "        0.00286461, 0.00254465, 0.00742488, 0.00553878, 0.01084537,\n",
       "        0.01008081, 0.00318964, 0.0057588 , 0.00308519, 0.00462656,\n",
       "        0.00197   , 0.00211176, 0.00186279, 0.00628706, 0.00230828,\n",
       "        0.00777944, 0.00729121, 0.00861947, 0.0038353 , 0.0062117 ,\n",
       "        0.00196587, 0.0174552 , 0.01161489, 0.00680862, 0.00761407,\n",
       "        0.00644154, 0.00360209, 0.00290336, 0.00175314, 0.00293376,\n",
       "        0.00293893, 0.0027551 , 0.00283733, 0.01355323, 0.00886212,\n",
       "        0.00484888, 0.00303266, 0.00719321, 0.00209282, 0.00378182,\n",
       "        0.0056027 , 0.01194475, 0.00403891, 0.00603199, 0.00208224,\n",
       "        0.00451331, 0.00150493, 0.00120861, 0.00212597, 0.00390341,\n",
       "        0.00165292, 0.000777  , 0.0012668 , 0.00330939, 0.00127416,\n",
       "        0.00082561, 0.0023662 , 0.00469647, 0.00304717, 0.0020838 ,\n",
       "        0.00142814, 0.03292444, 0.00473673, 0.00595461, 0.01100551,\n",
       "        0.01432091, 0.00186355, 0.00259331, 0.00139216, 0.004387  ,\n",
       "        0.00110424, 0.00133096, 0.00249223, 0.00408004, 0.00360108,\n",
       "        0.00113963, 0.00252028, 0.00380316, 0.00235908, 0.00222708,\n",
       "        0.01598696, 0.01468844, 0.00162233, 0.0011103 , 0.00175867,\n",
       "        0.00521145, 0.00396879, 0.00361789, 0.0059352 , 0.00284002,\n",
       "        0.00248756, 0.00130026, 0.0016357 , 0.00874317, 0.0013985 ,\n",
       "        0.00292638, 0.00093815, 0.00276093, 0.00266905, 0.00107722,\n",
       "        0.00760067, 0.0083092 , 0.0020327 , 0.00048075, 0.00180788]),\n",
       " 'mean_score_time': array([0.00378752, 0.00228765, 0.00239062, 0.00249653, 0.00419114,\n",
       "        0.00219469, 0.0036911 , 0.00348604, 0.00648186, 0.00189376,\n",
       "        0.00258911, 0.00278525, 0.0036901 , 0.00199051, 0.00199509,\n",
       "        0.00249848, 0.00428853, 0.00191801, 0.00209246, 0.0023927 ,\n",
       "        0.00339103, 0.00199049, 0.00229449, 0.00289667, 0.00379045,\n",
       "        0.00199659, 0.00240057, 0.00239656, 0.0041882 , 0.00169272,\n",
       "        0.0022918 , 0.00289292, 0.00598404, 0.00199556, 0.00278473,\n",
       "        0.00329483, 0.00468352, 0.00199723, 0.00199568, 0.00259645,\n",
       "        0.00356977, 0.00199761, 0.00229671, 0.0022917 , 0.00408936,\n",
       "        0.0018955 , 0.00219433, 0.00209527, 0.00379238, 0.00179889,\n",
       "        0.00251071, 0.00249407, 0.0039923 , 0.00259354, 0.00259428,\n",
       "        0.00309126, 0.00338821, 0.00179887, 0.00199566, 0.0025907 ,\n",
       "        0.0030915 , 0.00209458, 0.00229509, 0.00209494, 0.00398927,\n",
       "        0.00179474, 0.00239134, 0.00219476, 0.00358253, 0.0018959 ,\n",
       "        0.00219469, 0.00239391, 0.00448847, 0.00279365, 0.00339077,\n",
       "        0.00289435, 0.00628343, 0.00189569, 0.00259397, 0.00269334,\n",
       "        0.0035852 , 0.0019932 , 0.00219271, 0.00329165, 0.0051861 ,\n",
       "        0.00239415, 0.00229454, 0.0025913 , 0.00408385, 0.0022934 ,\n",
       "        0.00269277, 0.00368953, 0.00449011, 0.0018935 , 0.00279319,\n",
       "        0.00229664, 0.004388  , 0.00189447, 0.00239129, 0.00309396,\n",
       "        0.00320168, 0.00299261, 0.00239367, 0.00329146, 0.00408652,\n",
       "        0.00219214, 0.00229056, 0.00269024, 0.00488951, 0.00229433,\n",
       "        0.00249157, 0.00308759, 0.00429354, 0.00209568, 0.00229437,\n",
       "        0.00249503, 0.00428643, 0.00189505, 0.00219498, 0.00249431,\n",
       "        0.00339155, 0.00189571, 0.0026933 , 0.00528553, 0.00468478,\n",
       "        0.0024919 , 0.00239425, 0.00398967, 0.0052866 , 0.00189378,\n",
       "        0.002195  , 0.00259361, 0.00498409, 0.00359032, 0.00259364,\n",
       "        0.00378942, 0.00727975, 0.00299311, 0.00279317, 0.00289292,\n",
       "        0.00359392, 0.00220246, 0.00219696, 0.00289228, 0.00458791,\n",
       "        0.0021966 , 0.00219347, 0.0026901 , 0.00509157, 0.00198977,\n",
       "        0.00229428, 0.00239112, 0.00388978, 0.00179579, 0.00199535,\n",
       "        0.00259347, 0.0040916 , 0.00189586, 0.00229712, 0.00249407,\n",
       "        0.00309165, 0.00229483, 0.00239215, 0.00289338, 0.00349264,\n",
       "        0.00199404, 0.0020962 , 0.00249112, 0.00418708, 0.00169468,\n",
       "        0.00199287, 0.00259352, 0.00359063, 0.0019969 , 0.00219483,\n",
       "        0.00269103, 0.00398688, 0.0020952 , 0.00219498, 0.00229447,\n",
       "        0.00319395, 0.002595  , 0.00289261, 0.00269365, 0.00349319,\n",
       "        0.00199811, 0.00199552, 0.0025939 , 0.00458505, 0.0022887 ,\n",
       "        0.0020926 , 0.00249379, 0.00378966, 0.00179527, 0.00219514,\n",
       "        0.00289192, 0.00390561, 0.00199251, 0.00209482, 0.00249386,\n",
       "        0.00309193, 0.00199444, 0.0025939 , 0.00299151, 0.00299096,\n",
       "        0.0019954 , 0.00199552, 0.00258708, 0.00339332, 0.00209439,\n",
       "        0.00209782, 0.00229497, 0.00389442, 0.00199571, 0.00209501,\n",
       "        0.00229473, 0.00349097, 0.00208707, 0.00209513, 0.00289295,\n",
       "        0.00339034, 0.00249434, 0.00339038, 0.00289295, 0.0032943 ,\n",
       "        0.00179582, 0.0019954 , 0.00219181, 0.00378983, 0.00238976,\n",
       "        0.00299494, 0.00299361, 0.00488346, 0.00189481, 0.0022959 ,\n",
       "        0.0027926 , 0.00418882, 0.00189519, 0.00219426, 0.00279627,\n",
       "        0.00458913, 0.00279334, 0.00379004, 0.00219374, 0.00308924,\n",
       "        0.00169594, 0.00239618, 0.00259378, 0.00378876, 0.00199337,\n",
       "        0.0020947 , 0.00229428, 0.00368741, 0.00199578, 0.00229483,\n",
       "        0.00249426, 0.00379279, 0.00179703, 0.00279324, 0.00259335,\n",
       "        0.00358994, 0.00199158, 0.00189354, 0.00199547, 0.00329118,\n",
       "        0.00199578, 0.00229695, 0.00219188, 0.00368905, 0.00209382,\n",
       "        0.00209491, 0.00229421, 0.00408888, 0.00189316, 0.00199535,\n",
       "        0.00259588, 0.00366919, 0.00239506, 0.00249465, 0.00329149,\n",
       "        0.00329065, 0.00179658, 0.00209579, 0.00209494, 0.00299449,\n",
       "        0.0017966 , 0.00209508, 0.00199299, 0.00478714, 0.00179384,\n",
       "        0.00219753, 0.00259383, 0.00388947, 0.00199194, 0.00209506,\n",
       "        0.00259066, 0.00379002, 0.00219605, 0.00229418, 0.00299258,\n",
       "        0.00309036, 0.00219646, 0.0022006 , 0.00199537, 0.00309339,\n",
       "        0.0016957 , 0.00249128, 0.00229971, 0.00380182, 0.00179417,\n",
       "        0.00249376, 0.00299273, 0.00438848, 0.00199947, 0.00229139,\n",
       "        0.00239413, 0.00440323, 0.00249414, 0.00329123, 0.00249422,\n",
       "        0.00329664, 0.00189528, 0.0019942 , 0.00199287, 0.00289323,\n",
       "        0.00189512, 0.0021924 , 0.00199425, 0.00438576, 0.00219462,\n",
       "        0.00199463, 0.00269337, 0.00389173, 0.00199466, 0.00219738,\n",
       "        0.00249414, 0.00388958, 0.00269351, 0.00269072, 0.0024914 ,\n",
       "        0.00309052, 0.00189455, 0.00198963, 0.00209758, 0.00318611,\n",
       "        0.00189784, 0.00209551, 0.00229404, 0.00388987, 0.00189381,\n",
       "        0.00229177, 0.00239594, 0.00369263, 0.00199411, 0.00209694,\n",
       "        0.00249436, 0.00518634, 0.00309184, 0.00348842, 0.00379064,\n",
       "        0.00359063, 0.00199406, 0.0019881 , 0.00199785, 0.00339081,\n",
       "        0.00179234, 0.00219526, 0.00199528, 0.00359051, 0.00189209,\n",
       "        0.00239644, 0.00249326, 0.00398681, 0.00179322, 0.00239697,\n",
       "        0.00269315, 0.0048862 , 0.00189569, 0.00229437, 0.00239401,\n",
       "        0.00398636, 0.00219443, 0.00259373, 0.00209515, 0.00299032,\n",
       "        0.00209846, 0.0021971 , 0.00199533, 0.00339351, 0.00169814,\n",
       "        0.00209486, 0.00239248, 0.00408647, 0.00179274, 0.00209477,\n",
       "        0.00289295, 0.0045877 , 0.00199394, 0.00229261, 0.00229664]),\n",
       " 'std_score_time': array([3.97687679e-04, 4.55717359e-04, 4.81491477e-04, 5.01113553e-04,\n",
       "        5.98279674e-04, 5.98176448e-04, 1.18394370e-03, 6.65063216e-04,\n",
       "        2.32782357e-03, 2.97745022e-04, 7.99649099e-04, 3.95280558e-04,\n",
       "        4.57122053e-04, 5.66694432e-06, 8.32760296e-07, 9.17434365e-04,\n",
       "        1.18544945e-03, 3.10181106e-04, 2.99682750e-04, 4.89569735e-04,\n",
       "        4.83357576e-04, 1.17209105e-05, 6.46582815e-04, 9.37885552e-04,\n",
       "        9.80995146e-04, 8.49991493e-06, 4.90680497e-04, 4.92308358e-04,\n",
       "        6.06458392e-04, 4.54255019e-04, 4.53287498e-04, 1.21797345e-03,\n",
       "        2.09228295e-03, 4.46277154e-04, 5.91865044e-04, 7.80943448e-04,\n",
       "        8.90824267e-04, 4.46307073e-04, 1.15519891e-05, 6.58880025e-04,\n",
       "        4.75901497e-04, 4.51202562e-04, 4.54864304e-04, 4.53457502e-04,\n",
       "        1.21776243e-03, 2.99001082e-04, 3.99149546e-04, 2.99200324e-04,\n",
       "        8.70122950e-04, 4.00762050e-04, 9.64605065e-04, 4.99069265e-04,\n",
       "        6.34998374e-04, 7.97403015e-04, 6.62063262e-04, 8.27810017e-04,\n",
       "        4.85262475e-04, 4.00566671e-04, 5.76164530e-07, 4.86183290e-04,\n",
       "        2.99240241e-04, 2.99997827e-04, 4.56805382e-04, 2.99310950e-04,\n",
       "        1.41046961e-03, 3.98671284e-04, 4.85817753e-04, 3.98993606e-04,\n",
       "        4.87482579e-04, 2.99375043e-04, 3.98791174e-04, 6.61738571e-04,\n",
       "        1.11469048e-03, 5.98344504e-04, 9.14389115e-04, 8.28806512e-04,\n",
       "        2.52505828e-03, 5.37216374e-04, 6.61300513e-04, 6.38691157e-04,\n",
       "        9.11923721e-04, 4.40126928e-04, 3.99930298e-04, 1.09721107e-03,\n",
       "        1.39622703e-03, 4.88071702e-04, 4.57111269e-04, 6.60165952e-04,\n",
       "        1.03241758e-03, 6.38565207e-04, 1.00210442e-03, 8.96851839e-04,\n",
       "        6.67782635e-04, 2.98640098e-04, 5.97873351e-04, 4.55231228e-04,\n",
       "        1.11036789e-03, 5.36417706e-04, 4.90322097e-04, 1.13292402e-03,\n",
       "        4.15318305e-04, 1.47938729e-03, 7.98251336e-04, 1.00200665e-03,\n",
       "        1.29837266e-03, 3.99787881e-04, 6.32609338e-04, 4.61336612e-04,\n",
       "        1.13085952e-03, 6.38342871e-04, 6.67512092e-04, 8.29150182e-04,\n",
       "        4.59907649e-04, 2.99070700e-04, 4.56648278e-04, 5.00294816e-04,\n",
       "        4.59680607e-04, 2.99161344e-04, 3.98767147e-04, 4.99177537e-04,\n",
       "        4.89545883e-04, 2.99151893e-04, 1.00164410e-03, 5.27637960e-03,\n",
       "        1.00372330e-03, 6.64342475e-04, 4.89022611e-04, 1.26097478e-03,\n",
       "        1.67084991e-03, 2.98070874e-04, 3.99172690e-04, 4.88597160e-04,\n",
       "        2.71456171e-03, 1.19586053e-03, 9.14169992e-04, 7.47824811e-04,\n",
       "        3.62540627e-03, 1.41225764e-03, 1.16304782e-03, 9.35231331e-04,\n",
       "        9.13995881e-04, 5.96205412e-04, 4.05278402e-04, 8.28378046e-04,\n",
       "        1.73957437e-03, 7.46117089e-04, 3.97081494e-04, 4.55362353e-04,\n",
       "        1.63429086e-03, 4.42334605e-04, 4.51410753e-04, 6.59683110e-04,\n",
       "        5.37206861e-04, 3.99124743e-04, 5.27223215e-07, 4.88285962e-04,\n",
       "        1.21920161e-03, 2.99493668e-04, 4.60892046e-04, 4.98509822e-04,\n",
       "        5.36888213e-04, 4.57810196e-04, 4.86489207e-04, 6.98456317e-04,\n",
       "        9.18226521e-04, 4.51008304e-06, 2.99067621e-04, 9.12467438e-04,\n",
       "        8.70878939e-04, 4.55928616e-04, 8.02663687e-06, 4.88811827e-04,\n",
       "        4.88169884e-04, 6.31454280e-04, 3.99017505e-04, 6.37766268e-04,\n",
       "        4.40177415e-04, 5.37481534e-04, 3.98767389e-04, 4.57106283e-04,\n",
       "        7.45792982e-04, 6.60527147e-04, 8.27990010e-04, 4.57113146e-04,\n",
       "        9.18306038e-04, 4.51850977e-04, 2.56784668e-07, 4.88101031e-04,\n",
       "        9.15895263e-04, 8.99264441e-04, 2.99708883e-04, 4.98509498e-04,\n",
       "        3.99351931e-04, 5.96242286e-04, 3.99042031e-04, 5.32282559e-04,\n",
       "        3.07362775e-04, 4.42240601e-04, 2.99271222e-04, 4.98867174e-04,\n",
       "        2.99255594e-04, 4.45958840e-04, 6.61616911e-04, 6.29622517e-04,\n",
       "        1.34439330e-05, 1.48460514e-05, 3.33786011e-07, 6.51949717e-04,\n",
       "        4.86127674e-04, 2.99535790e-04, 3.07329843e-04, 4.57873515e-04,\n",
       "        5.33867617e-04, 9.40723701e-06, 2.98810176e-04, 4.56779408e-04,\n",
       "        4.98629289e-04, 3.02213993e-04, 2.99008842e-04, 6.98053294e-04,\n",
       "        6.61588380e-04, 6.68994988e-04, 9.12294087e-04, 9.40785608e-04,\n",
       "        4.61224054e-04, 3.98779628e-04, 4.13640775e-07, 4.00391823e-04,\n",
       "        8.69365193e-04, 6.60077974e-04, 1.09298963e-03, 1.09362803e-03,\n",
       "        1.13218041e-03, 5.37544677e-04, 4.55833354e-04, 5.97957181e-04,\n",
       "        1.24572519e-03, 5.37083179e-04, 5.98434872e-04, 7.42461404e-04,\n",
       "        1.19713643e-03, 1.24566079e-03, 1.07405078e-03, 5.98904394e-04,\n",
       "        2.99938187e-04, 4.57626971e-04, 4.88336487e-04, 6.62660673e-04,\n",
       "        3.98253310e-04, 4.17307438e-06, 2.99152159e-04, 4.56918983e-04,\n",
       "        6.37664576e-04, 9.86456691e-06, 4.56924536e-04, 4.98462380e-04,\n",
       "        5.99911930e-04, 5.99978145e-04, 8.69884770e-04, 6.62256288e-04,\n",
       "        7.98622533e-04, 9.25853358e-06, 5.32675646e-04, 5.76164530e-07,\n",
       "        6.38665077e-04, 6.23495355e-06, 4.55487703e-04, 3.99813899e-04,\n",
       "        4.58365966e-04, 5.36596969e-04, 2.99239406e-04, 4.57173680e-04,\n",
       "        8.28604870e-04, 5.36616564e-04, 6.25820386e-07, 6.66856966e-04,\n",
       "        8.49436983e-04, 7.98034882e-04, 6.69476076e-04, 1.18405747e-03,\n",
       "        6.39060737e-04, 3.99401736e-04, 2.90912899e-04, 2.99152140e-04,\n",
       "        4.46026387e-04, 3.99115440e-04, 2.99183802e-04, 8.84002593e-06,\n",
       "        1.46548320e-03, 3.97777067e-04, 3.97333292e-04, 4.89015942e-04,\n",
       "        2.99342653e-04, 4.46433589e-04, 2.99112429e-04, 4.86914729e-04,\n",
       "        3.98338504e-04, 7.45346574e-04, 4.56461373e-04, 6.30826661e-04,\n",
       "        3.00001189e-04, 5.95411508e-04, 3.96417332e-04, 5.30983387e-07,\n",
       "        2.98893235e-04, 4.56128391e-04, 4.96777179e-04, 4.59911961e-04,\n",
       "        8.99379963e-04, 3.98154888e-04, 6.69101438e-04, 7.72817922e-04,\n",
       "        1.10991824e-03, 4.45912557e-04, 4.57357457e-04, 6.61717158e-04,\n",
       "        1.01149912e-03, 8.03683673e-04, 7.79149386e-04, 4.99323511e-04,\n",
       "        6.41430212e-04, 2.98934900e-04, 4.46075606e-04, 4.46398588e-04,\n",
       "        2.99473428e-04, 2.98962639e-04, 3.94073518e-04, 2.63611607e-06,\n",
       "        1.19352713e-03, 3.98828997e-04, 1.49824785e-06, 8.98133508e-04,\n",
       "        9.41658597e-04, 4.46019976e-04, 6.06497430e-04, 6.69066067e-04,\n",
       "        5.36906374e-04, 7.79039186e-04, 6.33468232e-04, 6.67204782e-04,\n",
       "        2.99753586e-04, 2.98865864e-04, 1.00416120e-05, 3.06376640e-04,\n",
       "        3.88981388e-04, 5.42684350e-04, 2.99200229e-04, 6.39428641e-04,\n",
       "        8.28641970e-04, 2.98703938e-04, 4.52671691e-04, 4.91120676e-04,\n",
       "        1.00537708e-03, 6.23905047e-04, 2.98577933e-04, 4.99037726e-04,\n",
       "        2.08311914e-03, 6.98053636e-04, 5.01097394e-04, 5.98439966e-04,\n",
       "        1.01739701e-03, 4.44271870e-04, 5.65112388e-06, 8.31749448e-06,\n",
       "        6.61408328e-04, 3.97121099e-04, 3.98684261e-04, 4.23822137e-07,\n",
       "        4.88752877e-04, 2.98058508e-04, 4.91698066e-04, 4.98462394e-04,\n",
       "        7.97505692e-06, 5.97560629e-04, 4.91370942e-04, 7.79176790e-04,\n",
       "        1.75301433e-03, 2.99223456e-04, 4.57012796e-04, 4.88383519e-04,\n",
       "        1.41109686e-03, 5.98741052e-04, 6.61444071e-04, 2.98286571e-04,\n",
       "        4.46150529e-04, 5.36498832e-04, 4.03642402e-04, 4.26496120e-07,\n",
       "        4.91798241e-04, 4.58435039e-04, 2.99414083e-04, 4.89790011e-04,\n",
       "        1.04164258e-03, 3.99529133e-04, 2.90477097e-04, 2.99526532e-04,\n",
       "        1.27694293e-03, 4.43780200e-04, 4.53943859e-04, 4.55428163e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12,\n",
       "                    12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "                    13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14,\n",
       "                    14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "                    14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16,\n",
       "                    16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "                    17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "                    17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "                    18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19,\n",
       "                    19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "                    19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1,\n",
       "                    1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1,\n",
       "                    1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1,\n",
       "                    1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1,\n",
       "                    1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid', 'rbf', 'linear',\n",
       "                    'poly', 'sigmoid', 'rbf', 'linear', 'poly', 'sigmoid',\n",
       "                    'rbf', 'linear', 'poly', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 2, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 2, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 2, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 2, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 2, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 2, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 2, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 3, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 3, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 3, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 3, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 3, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 3, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 3, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 3, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 3, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 4, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 4, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 4, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 4, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 4, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 4, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 4, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 4, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 4, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 4, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 4, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 5, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 5, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 5, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 5, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 5, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 6, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 6, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 6, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 6, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 6, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 6, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 6, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 6, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 6, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 6, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 6, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 6, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 6, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 6, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 6, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 6, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 7, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 7, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 7, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 7, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 7, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 7, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 7, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 7, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 7, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 7, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 7, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 7, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 7, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 7, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 7, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 7, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 8, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 8, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 8, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 8, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 8, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 8, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 8, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 8, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 8, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 8, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 8, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 9, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 9, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 9, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 9, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 9, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 9, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 9, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 9, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 9, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 9, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 9, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 9, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 9, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 9, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 9, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 9, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 11, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 11, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 11, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 11, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 11, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 11, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 11, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 11, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 11, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 11, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 11, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 11, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 11, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 11, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 11, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 11, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 11, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 11, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 11, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 11, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 12, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 12, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 12, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 12, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 12, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 12, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 12, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 12, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 12, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 12, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 12, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 12, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 12, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 12, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 12, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 12, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 12, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 12, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 12, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 12, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 13, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 13, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 13, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 13, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 13, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 13, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 13, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 13, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 13, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 13, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 13, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 13, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 13, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 13, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 13, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 13, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 13, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 13, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 13, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 13, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 14, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 14, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 14, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 14, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 14, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 14, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 14, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 14, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 14, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 14, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 14, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 14, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 14, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 14, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 14, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 14, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 14, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 14, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 14, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 14, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 15, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 15, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 15, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 15, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 15, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 15, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 15, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 15, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 15, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 15, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 15, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 15, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 15, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 15, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 15, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 15, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 15, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 15, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 15, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 15, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 16, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 16, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 16, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 16, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 16, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 16, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 16, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 16, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 16, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 16, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 16, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 16, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 16, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 16, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 16, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 17, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 17, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 17, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 17, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 17, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 17, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 17, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 17, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 17, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 17, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 17, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 17, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 17, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 17, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 17, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 17, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 17, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 17, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 17, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 17, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 18, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 18, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 18, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 18, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 18, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 18, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 18, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 18, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 18, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 18, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 18, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 18, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 18, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 18, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 18, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 18, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 18, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 18, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 18, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 18, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 19, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 19, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 19, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 19, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 19, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 19, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 19, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 19, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 19, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 19, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 19, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 19, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 19, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 19, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 19, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 19, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 19, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 19, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 19, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 19, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 20, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 20, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 20, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 20, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 20, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 20, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 20, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 20, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 20, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 20, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 20, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 20, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 20, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 20, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 20, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 20, 'gamma': 0.0001, 'kernel': 'sigmoid'}],\n",
       " 'split0_test_score': array([0.90361446, 0.91566265, 0.91566265, 0.91566265, 0.92771084,\n",
       "        0.91566265, 0.8313253 , 0.84337349, 0.8313253 , 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.90361446, 0.92771084, 0.91566265,\n",
       "        0.90361446, 0.8313253 , 0.92771084, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.90361446, 0.89156627, 0.91566265,\n",
       "        0.90361446, 0.8313253 , 0.91566265, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.90361446, 0.87951807, 0.91566265,\n",
       "        0.90361446, 0.8313253 , 0.91566265, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.90361446, 0.92771084, 0.91566265,\n",
       "        0.90361446, 0.8313253 , 0.91566265, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.89156627, 0.90361446, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.84337349, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.91566265, 0.85542169, 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.91566265, 0.89156627, 0.86746988, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.91566265, 0.92771084, 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.86746988, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.86746988, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.87951807, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.84337349, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.85542169, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.8313253 , 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.91566265, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.85542169, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.86746988, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.92771084, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.87951807, 0.91566265,\n",
       "        0.91566265, 0.8313253 , 0.91566265, 0.91566265, 0.91566265,\n",
       "        0.8313253 , 0.92771084, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.85542169, 0.91566265,\n",
       "        0.91566265, 0.8313253 , 0.90361446, 0.91566265, 0.91566265,\n",
       "        0.8313253 , 0.92771084, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ]),\n",
       " 'split1_test_score': array([0.92771084, 0.92771084, 0.89156627, 0.93975904, 0.89156627,\n",
       "        0.92771084, 0.8313253 , 0.85542169, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.92771084, 0.90361446, 0.91566265, 0.93975904,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.87951807, 0.93975904,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.92771084, 0.90361446, 0.87951807, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.93975904, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.89156627, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.93975904, 0.85542169, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.89156627, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.93975904, 0.86746988, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.87951807, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.93975904, 0.87951807, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.89156627, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.89156627, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.89156627, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.89156627, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.85542169, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.87951807, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.86746988, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.86746988, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.86746988, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.84337349, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.84337349, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.85542169, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.85542169, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.91566265, 0.85542169, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.93975904, 0.92771084,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.85542169, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.93975904, 0.92771084,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.85542169, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.93975904, 0.92771084,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.95180723, 0.92771084, 0.90361446, 0.84337349, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.93975904, 0.92771084,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ]),\n",
       " 'split2_test_score': array([0.90361446, 0.91566265, 0.91566265, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.8313253 , 0.8313253 , 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.92771084, 0.86746988, 0.91566265, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.89156627, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.86746988, 0.91566265, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.93975904, 0.86746988, 0.92771084, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.8313253 , 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.92771084, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.8313253 , 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.93975904, 0.87951807, 0.91566265, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.84337349, 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.91566265, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.85542169, 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.90361446, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.91566265, 0.89156627, 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.89156627, 0.89156627, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.91566265, 0.90361446, 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.87951807, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.91566265, 0.89156627, 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.93975904, 0.87951807, 0.87951807, 0.91566265,\n",
       "        0.93975904, 0.8313253 , 0.91566265, 0.90361446, 0.93975904,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.93975904, 0.87951807, 0.89156627, 0.93975904,\n",
       "        0.93975904, 0.8313253 , 0.91566265, 0.89156627, 0.93975904,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.93975904, 0.87951807, 0.91566265, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.90361446, 0.93975904,\n",
       "        0.8313253 , 0.85542169, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.93975904, 0.87951807, 0.89156627, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.91566265, 0.90361446, 0.93975904,\n",
       "        0.8313253 , 0.85542169, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.87951807, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.90361446, 0.93975904,\n",
       "        0.8313253 , 0.86746988, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.90361446, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.87951807, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.87951807, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.93975904, 0.87951807, 0.89156627, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.93975904, 0.87951807, 0.89156627, 0.92771084,\n",
       "        0.93975904, 0.8313253 , 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.93975904, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.93975904, 0.8313253 , 0.8313253 ]),\n",
       " 'split3_test_score': array([0.90361446, 0.90361446, 0.90361446, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.8313253 , 0.8313253 , 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.91566265, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.84337349, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.89156627, 0.86746988, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.90361446, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.89156627, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.89156627, 0.90361446, 0.86746988, 0.90361446,\n",
       "        0.89156627, 0.8313253 , 0.90361446, 0.90361446, 0.89156627,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.89156627, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.89156627, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.89156627, 0.90361446, 0.87951807, 0.90361446,\n",
       "        0.89156627, 0.8313253 , 0.90361446, 0.90361446, 0.89156627,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.89156627, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.89156627, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.91566265, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.91566265, 0.86746988, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.92771084, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.92771084, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ]),\n",
       " 'split4_test_score': array([0.90361446, 0.90361446, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.8313253 , 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.89156627, 0.90361446, 0.89156627, 0.89156627,\n",
       "        0.89156627, 0.8313253 , 0.90361446, 0.8313253 , 0.89156627,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.89156627, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.89156627, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.89156627, 0.8313253 , 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.91566265, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.8313253 , 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.91566265, 0.90361446, 0.87951807, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.8313253 , 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.91566265, 0.86746988, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.87951807, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.90361446, 0.91566265, 0.85542169, 0.90361446,\n",
       "        0.90361446, 0.8313253 , 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.90361446, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.90361446, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.91566265, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.90361446, 0.89156627, 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.85542169, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.86746988, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.91566265, 0.91566265, 0.85542169, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.90361446, 0.90361446, 0.91566265,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.91566265, 0.91566265, 0.87951807, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.90361446, 0.89156627, 0.91566265,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.91566265, 0.91566265, 0.86746988, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.90361446, 0.91566265,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.91566265, 0.91566265, 0.86746988, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.89156627, 0.91566265,\n",
       "        0.8313253 , 0.87951807, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.91566265, 0.86746988, 0.90361446,\n",
       "        0.92771084, 0.8313253 , 0.89156627, 0.89156627, 0.92771084,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.91566265, 0.84337349, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.89156627, 0.89156627, 0.92771084,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.91566265, 0.90361446, 0.86746988, 0.91566265,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.89156627, 0.91566265,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.91566265, 0.90361446, 0.85542169, 0.91566265,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.89156627, 0.91566265,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.91566265, 0.90361446, 0.86746988, 0.90361446,\n",
       "        0.91566265, 0.8313253 , 0.89156627, 0.89156627, 0.91566265,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ]),\n",
       " 'split5_test_score': array([0.91566265, 0.92771084, 0.90361446, 0.93975904, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.84337349, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.91566265, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.91566265, 0.8313253 , 0.91566265, 0.8313253 , 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.91566265, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.91566265, 0.8313253 , 0.92771084, 0.8313253 , 0.91566265,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.91566265, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.91566265, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.92771084, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.8313253 , 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.92771084, 0.93975904, 0.91566265, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.84337349, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.90361446, 0.92771084, 0.93975904, 0.91566265, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.84337349, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.91566265, 0.92771084, 0.93975904, 0.91566265, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.86746988, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.89156627, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.90361446, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.8313253 , 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.91566265, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.92771084, 0.91566265, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.92771084, 0.90361446, 0.91566265,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.84337349, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.91566265, 0.91566265, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.86746988, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.86746988, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.89156627, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.90361446, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.90361446, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ,\n",
       "        0.93975904, 0.92771084, 0.90361446, 0.91566265, 0.92771084,\n",
       "        0.92771084, 0.8313253 , 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.8313253 , 0.91566265, 0.8313253 , 0.92771084, 0.8313253 ,\n",
       "        0.8313253 , 0.8313253 , 0.92771084, 0.8313253 , 0.8313253 ]),\n",
       " 'split6_test_score': array([0.91463415, 0.90243902, 0.90243902, 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.84146341, 0.84146341, 0.84146341, 0.90243902,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.90243902, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.90243902, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.8902439 , 0.8902439 ,\n",
       "        0.90243902, 0.84146341, 0.91463415, 0.84146341, 0.90243902,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.90243902, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.90243902, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.91463415, 0.91463415, 0.87804878, 0.90243902,\n",
       "        0.91463415, 0.84146341, 0.8902439 , 0.84146341, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.91463415, 0.87804878, 0.90243902,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.84146341, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.92682927, 0.91463415, 0.86585366, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.91463415, 0.84146341, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.92682927, 0.91463415, 0.86585366, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.91463415, 0.85365854, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.86585366, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.87804878, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.86585366, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.87804878, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.85365854, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.8902439 , 0.86585366, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.8902439 , 0.85365854, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.8902439 , 0.92682927,\n",
       "        0.84146341, 0.87804878, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.84146341, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.8902439 , 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.84146341, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.8902439 , 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.85365854, 0.90243902,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.8902439 , 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.85365854, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.8902439 , 0.92682927,\n",
       "        0.84146341, 0.91463415, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.85365854, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.91463415, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.85365854, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.91463415, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.84146341, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.91463415, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341]),\n",
       " 'split7_test_score': array([0.91463415, 0.91463415, 0.91463415, 0.90243902, 0.92682927,\n",
       "        0.91463415, 0.84146341, 0.84146341, 0.84146341, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.91463415, 0.8902439 , 0.8902439 , 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.92682927, 0.84146341, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.90243902, 0.8902439 , 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.84146341, 0.92682927, 0.84146341, 0.90243902,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.90243902, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.90243902, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.90243902, 0.8902439 , 0.87804878, 0.91463415,\n",
       "        0.90243902, 0.84146341, 0.90243902, 0.84146341, 0.90243902,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.90243902, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.90243902, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.90243902, 0.87804878, 0.8902439 , 0.91463415,\n",
       "        0.90243902, 0.84146341, 0.90243902, 0.84146341, 0.90243902,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.90243902, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.90243902, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.91463415, 0.87804878, 0.87804878, 0.90243902,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.85365854, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.91463415, 0.8902439 , 0.8902439 , 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.86585366, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.8902439 , 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.8902439 , 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.87804878, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.90243902, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.87804878, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.91463415, 0.92682927, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.87804878, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.87804878, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.91463415, 0.91463415,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.87804878, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.86585366, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.84146341, 0.86585366, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.86585366, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.84146341, 0.86585366, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.86585366, 0.91463415,\n",
       "        0.91463415, 0.84146341, 0.90243902, 0.91463415, 0.91463415,\n",
       "        0.84146341, 0.8902439 , 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.92682927, 0.8902439 , 0.87804878, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.90243902, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.87804878, 0.87804878, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.90243902, 0.90243902, 0.93902439,\n",
       "        0.84146341, 0.91463415, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.87804878, 0.87804878, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.90243902, 0.90243902, 0.93902439,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.87804878, 0.87804878, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.90243902, 0.93902439,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341]),\n",
       " 'split8_test_score': array([0.91463415, 0.91463415, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.84146341, 0.85365854, 0.84146341, 0.91463415,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.91463415, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.91463415, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.93902439, 0.92682927, 0.92682927, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.90243902, 0.84146341, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.93902439, 0.92682927, 0.90243902, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.84146341, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.93902439, 0.92682927, 0.91463415, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.84146341, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.93902439, 0.92682927, 0.87804878, 0.91463415,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.85365854, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.95121951, 0.91463415, 0.87804878, 0.91463415,\n",
       "        0.95121951, 0.84146341, 0.91463415, 0.85365854, 0.95121951,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.95121951, 0.91463415, 0.90243902, 0.93902439,\n",
       "        0.95121951, 0.84146341, 0.91463415, 0.87804878, 0.95121951,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.95121951, 0.92682927, 0.87804878, 0.93902439,\n",
       "        0.95121951, 0.84146341, 0.91463415, 0.8902439 , 0.95121951,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.92682927, 0.92682927, 0.86585366, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.91463415, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.95121951, 0.92682927, 0.92682927, 0.86585366, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.91463415, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.92682927, 0.87804878, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.91463415, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.87804878, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.92682927, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.85365854, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.92682927, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.87804878, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.85365854, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.92682927, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.87804878, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.87804878, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.91463415, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.87804878, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.92682927, 0.93902439, 0.8902439 , 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.8902439 , 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.92682927, 0.93902439, 0.87804878, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.8902439 , 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.92682927, 0.93902439, 0.87804878, 0.93902439,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.87804878, 0.95121951,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.86585366, 0.95121951,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.91463415, 0.92682927,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341]),\n",
       " 'split9_test_score': array([0.92682927, 0.92682927, 0.91463415, 0.90243902, 0.92682927,\n",
       "        0.92682927, 0.84146341, 0.85365854, 0.84146341, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.92682927, 0.95121951, 0.90243902, 0.91463415,\n",
       "        0.92682927, 0.84146341, 0.92682927, 0.84146341, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.93902439, 0.92682927, 0.8902439 , 0.92682927,\n",
       "        0.93902439, 0.84146341, 0.90243902, 0.84146341, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.93902439, 0.92682927, 0.90243902, 0.92682927,\n",
       "        0.93902439, 0.84146341, 0.92682927, 0.84146341, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.92682927, 0.93902439, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.93902439, 0.84146341, 0.93902439, 0.85365854, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.92682927, 0.90243902, 0.92682927,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.87804878, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.92682927, 0.8902439 , 0.92682927,\n",
       "        0.92682927, 0.84146341, 0.92682927, 0.90243902, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.93902439, 0.92682927, 0.92682927, 0.90243902, 0.92682927,\n",
       "        0.92682927, 0.84146341, 0.93902439, 0.92682927, 0.92682927,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.92682927, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.92682927, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.93902439, 0.91463415, 0.90243902, 0.92682927,\n",
       "        0.93902439, 0.84146341, 0.92682927, 0.92682927, 0.93902439,\n",
       "        0.84146341, 0.84146341, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.91463415, 0.93902439, 0.90243902, 0.87804878, 0.92682927,\n",
       "        0.93902439, 0.84146341, 0.92682927, 0.92682927, 0.93902439,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.91463415, 0.87804878, 0.92682927,\n",
       "        0.93902439, 0.84146341, 0.92682927, 0.92682927, 0.93902439,\n",
       "        0.84146341, 0.85365854, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.95121951, 0.91463415, 0.86585366, 0.92682927,\n",
       "        0.95121951, 0.84146341, 0.92682927, 0.92682927, 0.95121951,\n",
       "        0.84146341, 0.87804878, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.95121951, 0.90243902, 0.85365854, 0.92682927,\n",
       "        0.95121951, 0.84146341, 0.92682927, 0.92682927, 0.95121951,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.95121951, 0.90243902, 0.85365854, 0.93902439,\n",
       "        0.95121951, 0.84146341, 0.92682927, 0.91463415, 0.95121951,\n",
       "        0.84146341, 0.90243902, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.95121951, 0.8902439 , 0.85365854, 0.93902439,\n",
       "        0.95121951, 0.84146341, 0.92682927, 0.91463415, 0.95121951,\n",
       "        0.84146341, 0.91463415, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.8902439 , 0.95121951, 0.8902439 , 0.86585366, 0.93902439,\n",
       "        0.95121951, 0.84146341, 0.92682927, 0.91463415, 0.95121951,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.95121951, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.95121951, 0.84146341, 0.84146341,\n",
       "        0.8902439 , 0.93902439, 0.8902439 , 0.86585366, 0.93902439,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.91463415, 0.93902439,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.8902439 , 0.86585366, 0.93902439,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.91463415, 0.93902439,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.8902439 , 0.84146341, 0.93902439,\n",
       "        0.93902439, 0.84146341, 0.91463415, 0.91463415, 0.93902439,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341,\n",
       "        0.90243902, 0.93902439, 0.90243902, 0.86585366, 0.93902439,\n",
       "        0.93902439, 0.84146341, 0.92682927, 0.92682927, 0.93902439,\n",
       "        0.84146341, 0.92682927, 0.84146341, 0.93902439, 0.84146341,\n",
       "        0.84146341, 0.84146341, 0.93902439, 0.84146341, 0.84146341]),\n",
       " 'mean_test_score': array([0.9128563 , 0.91525125, 0.90678813, 0.91400235, 0.9128563 ,\n",
       "        0.91525125, 0.83538055, 0.84263885, 0.83538055, 0.91525125,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.91525125, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.91525125, 0.83538055, 0.83538055,\n",
       "        0.92014399, 0.91528063, 0.90805172, 0.90675874, 0.91281222,\n",
       "        0.91528063, 0.83538055, 0.91406112, 0.83538055, 0.91528063,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.91528063, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.91528063, 0.83538055, 0.83538055,\n",
       "        0.92255363, 0.91770497, 0.90561269, 0.89587129, 0.91645607,\n",
       "        0.91770497, 0.83538055, 0.91040259, 0.83538055, 0.91770497,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.91770497, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.91770497, 0.83538055, 0.83538055,\n",
       "        0.92374376, 0.92131942, 0.90440788, 0.89707611, 0.91525125,\n",
       "        0.92131942, 0.83538055, 0.91523656, 0.83538055, 0.92131942,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.92131942, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92131942, 0.83538055, 0.83538055,\n",
       "        0.92616809, 0.92253894, 0.90680282, 0.89826624, 0.91525125,\n",
       "        0.92253894, 0.83538055, 0.91767558, 0.84143403, 0.92253894,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.92253894, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92253894, 0.83538055, 0.83538055,\n",
       "        0.92497796, 0.92496327, 0.90558331, 0.88978842, 0.91282692,\n",
       "        0.92496327, 0.83538055, 0.9188804 , 0.85595063, 0.92496327,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.92496327, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92496327, 0.83538055, 0.83538055,\n",
       "        0.9273876 , 0.92375845, 0.90678813, 0.88861299, 0.91770497,\n",
       "        0.92375845, 0.83538055, 0.91644138, 0.88017925, 0.92375845,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.92375845, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92375845, 0.83538055, 0.83538055,\n",
       "        0.92615339, 0.92496327, 0.90439318, 0.88861299, 0.91769027,\n",
       "        0.92496327, 0.83538055, 0.91525125, 0.89952983, 0.92496327,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.92496327, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92496327, 0.83538055, 0.83538055,\n",
       "        0.92612401, 0.92494857, 0.90558331, 0.87893036, 0.91770497,\n",
       "        0.92494857, 0.83538055, 0.91403174, 0.91041728, 0.92494857,\n",
       "        0.83538055, 0.83538055, 0.83538055, 0.92494857, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92494857, 0.83538055, 0.83538055,\n",
       "        0.92612401, 0.92615339, 0.9043638 , 0.87650602, 0.91528063,\n",
       "        0.92615339, 0.83538055, 0.91525125, 0.91406112, 0.92615339,\n",
       "        0.83538055, 0.84263885, 0.83538055, 0.92615339, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92615339, 0.83538055, 0.83538055,\n",
       "        0.92368498, 0.92615339, 0.90678813, 0.87528651, 0.91528063,\n",
       "        0.92615339, 0.83538055, 0.91282692, 0.91284161, 0.92615339,\n",
       "        0.83538055, 0.84506318, 0.83538055, 0.92615339, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92615339, 0.83538055, 0.83538055,\n",
       "        0.92368498, 0.92496327, 0.90921246, 0.87528651, 0.91769027,\n",
       "        0.92496327, 0.83538055, 0.91404643, 0.91041728, 0.92496327,\n",
       "        0.83538055, 0.85595063, 0.83538055, 0.92496327, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92496327, 0.83538055, 0.83538055,\n",
       "        0.92368498, 0.92496327, 0.90678813, 0.87161328, 0.91769027,\n",
       "        0.92496327, 0.83538055, 0.91525125, 0.91284161, 0.92496327,\n",
       "        0.83538055, 0.87411108, 0.83538055, 0.92496327, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92496327, 0.83538055, 0.83538055,\n",
       "        0.92368498, 0.92616809, 0.90800764, 0.86917426, 0.91890979,\n",
       "        0.92616809, 0.83538055, 0.91284161, 0.91403174, 0.92616809,\n",
       "        0.83538055, 0.88138407, 0.83538055, 0.92616809, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92616809, 0.83538055, 0.83538055,\n",
       "        0.9248898 , 0.92616809, 0.90556862, 0.86558919, 0.91890979,\n",
       "        0.92616809, 0.83538055, 0.91403174, 0.9116221 , 0.92616809,\n",
       "        0.83538055, 0.88862768, 0.83538055, 0.92616809, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92616809, 0.83538055, 0.83538055,\n",
       "        0.92245078, 0.92737291, 0.9043638 , 0.8800911 , 0.9201146 ,\n",
       "        0.92737291, 0.83538055, 0.91647076, 0.91281222, 0.92737291,\n",
       "        0.83538055, 0.90073465, 0.83538055, 0.92737291, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92737291, 0.83538055, 0.83538055,\n",
       "        0.92245078, 0.92737291, 0.90556862, 0.86683808, 0.92253894,\n",
       "        0.92737291, 0.83538055, 0.91525125, 0.91401704, 0.92737291,\n",
       "        0.83538055, 0.90678813, 0.83538055, 0.92737291, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92737291, 0.83538055, 0.83538055,\n",
       "        0.92246547, 0.9273876 , 0.90193947, 0.87165736, 0.92253894,\n",
       "        0.9273876 , 0.83538055, 0.91404643, 0.91401704, 0.9273876 ,\n",
       "        0.83538055, 0.91043197, 0.83538055, 0.9273876 , 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.9273876 , 0.83538055, 0.83538055,\n",
       "        0.92368498, 0.92618278, 0.90314428, 0.86921834, 0.92375845,\n",
       "        0.92618278, 0.83538055, 0.91404643, 0.91401704, 0.92618278,\n",
       "        0.83538055, 0.91165148, 0.83538055, 0.92618278, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92618278, 0.83538055, 0.83538055,\n",
       "        0.92248016, 0.92618278, 0.9043638 , 0.86801352, 0.92255363,\n",
       "        0.92618278, 0.83538055, 0.91528063, 0.91523656, 0.92618278,\n",
       "        0.83538055, 0.91406112, 0.83538055, 0.92618278, 0.83538055,\n",
       "        0.83538055, 0.83538055, 0.92618278, 0.83538055, 0.83538055]),\n",
       " 'std_test_score': array([0.00880287, 0.00938412, 0.0076183 , 0.01396307, 0.01167333,\n",
       "        0.00938412, 0.00496664, 0.00891123, 0.00496664, 0.00938412,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.00938412, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.00938412, 0.00496664, 0.00496664,\n",
       "        0.01428183, 0.01416403, 0.02088078, 0.01725216, 0.01421136,\n",
       "        0.01416403, 0.00496664, 0.01127215, 0.00496664, 0.01416403,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.01416403, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01416403, 0.00496664, 0.00496664,\n",
       "        0.01433873, 0.01396978, 0.01670246, 0.01553369, 0.01145203,\n",
       "        0.01396978, 0.00496664, 0.01353262, 0.00496664, 0.01396978,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.01396978, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01396978, 0.00496664, 0.00496664,\n",
       "        0.01532662, 0.01452152, 0.01722937, 0.01976285, 0.00938412,\n",
       "        0.01452152, 0.00496664, 0.01438893, 0.00496664, 0.01452152,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.01452152, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01452152, 0.00496664, 0.00496664,\n",
       "        0.01743044, 0.0144206 , 0.01945112, 0.02263627, 0.00938412,\n",
       "        0.0144206 , 0.00496664, 0.01509629, 0.00952387, 0.0144206 ,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.0144206 , 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.0144206 , 0.00496664, 0.00496664,\n",
       "        0.01845225, 0.01398625, 0.01928517, 0.01773533, 0.01058707,\n",
       "        0.01398625, 0.00496664, 0.01334348, 0.01350905, 0.01398625,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.01398625, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01398625, 0.00496664, 0.00496664,\n",
       "        0.01418682, 0.01421474, 0.01707974, 0.02008554, 0.01164759,\n",
       "        0.01421474, 0.00496664, 0.01276984, 0.01807614, 0.01421474,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.01421474, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01421474, 0.00496664, 0.00496664,\n",
       "        0.01575492, 0.01290671, 0.01644243, 0.0200678 , 0.01294692,\n",
       "        0.01290671, 0.00496664, 0.01214702, 0.01206982, 0.01290671,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.01290671, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01290671, 0.00496664, 0.00496664,\n",
       "        0.0158879 , 0.0104652 , 0.01293331, 0.01711646, 0.01164759,\n",
       "        0.0104652 , 0.00496664, 0.01014651, 0.01102929, 0.0104652 ,\n",
       "        0.00496664, 0.00496664, 0.00496664, 0.0104652 , 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.0104652 , 0.00496664, 0.00496664,\n",
       "        0.0158879 , 0.01001044, 0.01471882, 0.01691298, 0.01193969,\n",
       "        0.01001044, 0.00496664, 0.00938412, 0.01127215, 0.01001044,\n",
       "        0.00496664, 0.00891123, 0.00496664, 0.01001044, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01001044, 0.00496664, 0.00496664,\n",
       "        0.01735223, 0.01001044, 0.01430463, 0.01635089, 0.01193969,\n",
       "        0.01001044, 0.00496664, 0.01058707, 0.01048889, 0.01001044,\n",
       "        0.00496664, 0.01143922, 0.00496664, 0.01001044, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01001044, 0.00496664, 0.00496664,\n",
       "        0.01735223, 0.01498822, 0.01641238, 0.01339939, 0.01402336,\n",
       "        0.01498822, 0.00496664, 0.01139644, 0.01102929, 0.01498822,\n",
       "        0.00496664, 0.01350905, 0.00496664, 0.01498822, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01498822, 0.00496664, 0.00496664,\n",
       "        0.01735223, 0.01498822, 0.01533228, 0.02570831, 0.01294692,\n",
       "        0.01498822, 0.00496664, 0.01211766, 0.01406501, 0.01498822,\n",
       "        0.00496664, 0.0153546 , 0.00496664, 0.01498822, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01498822, 0.00496664, 0.00496664,\n",
       "        0.01735223, 0.0125394 , 0.01442609, 0.02558798, 0.01425826,\n",
       "        0.0125394 , 0.00496664, 0.01296458, 0.01151937, 0.0125394 ,\n",
       "        0.00496664, 0.01490271, 0.00496664, 0.0125394 , 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.0125394 , 0.00496664, 0.00496664,\n",
       "        0.01630342, 0.0125394 , 0.01609569, 0.02513389, 0.01425826,\n",
       "        0.0125394 , 0.00496664, 0.01268918, 0.01330764, 0.0125394 ,\n",
       "        0.00496664, 0.01602849, 0.00496664, 0.0125394 , 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.0125394 , 0.00496664, 0.00496664,\n",
       "        0.01760342, 0.01204103, 0.01574207, 0.02582624, 0.01339798,\n",
       "        0.01204103, 0.00496664, 0.01474766, 0.01315032, 0.01204103,\n",
       "        0.00496664, 0.01181336, 0.00496664, 0.01204103, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01204103, 0.00496664, 0.00496664,\n",
       "        0.01760342, 0.00924652, 0.01609569, 0.01697322, 0.01096111,\n",
       "        0.00924652, 0.00496664, 0.01433923, 0.01489616, 0.00924652,\n",
       "        0.00496664, 0.01210614, 0.00496664, 0.00924652, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.00924652, 0.00496664, 0.00496664,\n",
       "        0.01479892, 0.01061817, 0.0166894 , 0.01355946, 0.01096111,\n",
       "        0.01061817, 0.00496664, 0.01373517, 0.01386186, 0.01061817,\n",
       "        0.00496664, 0.01090571, 0.00496664, 0.01061817, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01061817, 0.00496664, 0.00496664,\n",
       "        0.01558962, 0.01118173, 0.01801855, 0.0187831 , 0.01318102,\n",
       "        0.01118173, 0.00496664, 0.01373517, 0.01386186, 0.01118173,\n",
       "        0.00496664, 0.01194021, 0.00496664, 0.01118173, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01118173, 0.00496664, 0.00496664,\n",
       "        0.01659613, 0.01118173, 0.01750967, 0.02136504, 0.01436355,\n",
       "        0.01118173, 0.00496664, 0.01416403, 0.01438893, 0.01118173,\n",
       "        0.00496664, 0.01127215, 0.00496664, 0.01118173, 0.00496664,\n",
       "        0.00496664, 0.00496664, 0.01118173, 0.00496664, 0.00496664]),\n",
       " 'rank_test_score': array([161, 136, 184, 160, 161, 136, 228, 225, 228, 136, 228, 228, 228,\n",
       "        136, 228, 228, 228, 136, 228, 228, 108, 127, 177, 185, 168, 127,\n",
       "        228, 148, 228, 127, 228, 228, 228, 127, 228, 228, 228, 127, 228,\n",
       "        228,  90, 113, 186, 202, 125, 113, 228, 175, 228, 113, 228, 228,\n",
       "        228, 113, 228, 228, 228, 113, 228, 228,  84, 103, 191, 201, 136,\n",
       "        103, 228, 146, 228, 103, 228, 228, 228, 103, 228, 228, 228, 103,\n",
       "        228, 228,  27,  92, 179, 200, 136,  92, 228, 123, 227,  92, 228,\n",
       "        228, 228,  92, 228, 228, 228,  92, 228, 228,  51,  52, 187, 203,\n",
       "        166,  52, 228, 112, 222,  52, 228, 228, 228,  52, 228, 228, 228,\n",
       "         52, 228, 228,   1,  78, 180, 206, 113,  78, 228, 126, 208,  78,\n",
       "        228, 228, 228,  78, 228, 228, 228,  78, 228, 228,  38,  52, 192,\n",
       "        205, 120,  52, 228, 136, 199,  52, 228, 228, 228,  52, 228, 228,\n",
       "        228,  52, 228, 228,  49,  72, 187, 210, 113,  72, 228, 154, 173,\n",
       "         72, 228, 228, 228,  72, 228, 228, 228,  72, 228, 228,  49,  38,\n",
       "        193, 211, 127,  38, 228, 136, 148,  38, 228, 225, 228,  38, 228,\n",
       "        228, 228,  38, 228, 228,  85,  38, 180, 212, 127,  38, 228, 166,\n",
       "        163,  38, 228, 224, 228,  38, 228, 228, 228,  38, 228, 228,  85,\n",
       "         52, 176, 212, 120,  52, 228, 151, 173,  52, 228, 222, 228,  52,\n",
       "        228, 228, 228,  52, 228, 228,  85,  52, 180, 216, 120,  52, 228,\n",
       "        135, 165,  52, 228, 214, 228,  52, 228, 228, 228,  52, 228, 228,\n",
       "         85,  27, 178, 218, 110,  27, 228, 163, 156,  27, 228, 207, 228,\n",
       "         27, 228, 228, 228,  27, 228, 228,  77,  27, 189, 221, 110,  27,\n",
       "        228, 154, 171,  27, 228, 204, 228,  27, 228, 228, 228,  27, 228,\n",
       "        228, 101,   7, 193, 209, 109,   7, 228, 124, 168,   7, 228, 198,\n",
       "        228,   7, 228, 228, 228,   7, 228, 228, 101,   7, 190, 220,  92,\n",
       "          7, 228, 136, 157,   7, 228, 180, 228,   7, 228, 228, 228,   7,\n",
       "        228, 228, 100,   1, 197, 215,  92,   1, 228, 152, 157,   1, 228,\n",
       "        172, 228,   1, 228, 228, 228,   1, 228, 228,  85,  17, 196, 217,\n",
       "         78,  17, 228, 152, 157,  17, 228, 170, 228,  17, 228, 228, 228,\n",
       "         17, 228, 228,  99,  17, 195, 219,  90,  17, 228, 127, 146,  17,\n",
       "        228, 148, 228,  17, 228, 228, 228,  17, 228, 228])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "GSCV_SVC = GridSearchCV(modelSVC,{\n",
    "    'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel':['rbf', 'linear', 'poly', 'sigmoid']\n",
    "}, \n",
    "cv = 10, \n",
    "return_train_score = False\n",
    ")\n",
    "GSCV_SVC.fit(X, Y)\n",
    "GSCV_SVC.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae33971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072907</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.912856</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915251</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049671</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.906788</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059637</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914002</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085865</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.912856</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.073699</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 20, 'gamma': 0.001, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.047079</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.926183</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0         0.072907      0.009937         0.003788        0.000398       1   \n",
       "1         0.041394      0.003462         0.002288        0.000456       1   \n",
       "2         0.049671      0.002594         0.002391        0.000481       1   \n",
       "3         0.059637      0.003642         0.002497        0.000501       1   \n",
       "4         0.085865      0.007816         0.004191        0.000598       1   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "395       0.073699      0.007601         0.002893        0.000300      20   \n",
       "396       0.187797      0.008309         0.004588        0.001277      20   \n",
       "397       0.047079      0.002033         0.001994        0.000444      20   \n",
       "398       0.036304      0.000481         0.002293        0.000454      20   \n",
       "399       0.057743      0.001808         0.002297        0.000455      20   \n",
       "\n",
       "    param_gamma param_kernel                                           params  \\\n",
       "0             1          rbf            {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "1             1       linear         {'C': 1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "2             1         poly           {'C': 1, 'gamma': 1, 'kernel': 'poly'}   \n",
       "3             1      sigmoid        {'C': 1, 'gamma': 1, 'kernel': 'sigmoid'}   \n",
       "4           0.1          rbf          {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "..          ...          ...                                              ...   \n",
       "395       0.001      sigmoid   {'C': 20, 'gamma': 0.001, 'kernel': 'sigmoid'}   \n",
       "396      0.0001          rbf      {'C': 20, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "397      0.0001       linear   {'C': 20, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "398      0.0001         poly     {'C': 20, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "399      0.0001      sigmoid  {'C': 20, 'gamma': 0.0001, 'kernel': 'sigmoid'}   \n",
       "\n",
       "     split0_test_score  split1_test_score  ...  split3_test_score  \\\n",
       "0             0.903614           0.927711  ...           0.903614   \n",
       "1             0.915663           0.927711  ...           0.903614   \n",
       "2             0.915663           0.891566  ...           0.903614   \n",
       "3             0.915663           0.939759  ...           0.903614   \n",
       "4             0.927711           0.891566  ...           0.915663   \n",
       "..                 ...                ...  ...                ...   \n",
       "395           0.831325           0.831325  ...           0.831325   \n",
       "396           0.831325           0.831325  ...           0.831325   \n",
       "397           0.915663           0.927711  ...           0.903614   \n",
       "398           0.831325           0.831325  ...           0.831325   \n",
       "399           0.831325           0.831325  ...           0.831325   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0             0.903614           0.915663           0.914634   \n",
       "1             0.903614           0.927711           0.902439   \n",
       "2             0.903614           0.903614           0.902439   \n",
       "3             0.903614           0.939759           0.902439   \n",
       "4             0.903614           0.915663           0.914634   \n",
       "..                 ...                ...                ...   \n",
       "395           0.831325           0.831325           0.841463   \n",
       "396           0.831325           0.831325           0.841463   \n",
       "397           0.915663           0.927711           0.926829   \n",
       "398           0.831325           0.831325           0.841463   \n",
       "399           0.831325           0.831325           0.841463   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0             0.914634           0.914634           0.926829         0.912856   \n",
       "1             0.914634           0.914634           0.926829         0.915251   \n",
       "2             0.914634           0.902439           0.914634         0.906788   \n",
       "3             0.902439           0.914634           0.902439         0.914002   \n",
       "4             0.926829           0.902439           0.926829         0.912856   \n",
       "..                 ...                ...                ...              ...   \n",
       "395           0.841463           0.841463           0.841463         0.835381   \n",
       "396           0.841463           0.841463           0.841463         0.835381   \n",
       "397           0.939024           0.926829           0.939024         0.926183   \n",
       "398           0.841463           0.841463           0.841463         0.835381   \n",
       "399           0.841463           0.841463           0.841463         0.835381   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "0          0.008803              161  \n",
       "1          0.009384              136  \n",
       "2          0.007618              184  \n",
       "3          0.013963              160  \n",
       "4          0.011673              161  \n",
       "..              ...              ...  \n",
       "395        0.004967              228  \n",
       "396        0.004967              228  \n",
       "397        0.011182               17  \n",
       "398        0.004967              228  \n",
       "399        0.004967              228  \n",
       "\n",
       "[400 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svc_grid = pd.DataFrame(GSCV_SVC.cv_results_)\n",
    "df_svc_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ea9f0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.912856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.915251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.906788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.914002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.912856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>20</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.926183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>20</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>20</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C param_kernel  mean_test_score\n",
       "0         1          rbf         0.912856\n",
       "1         1       linear         0.915251\n",
       "2         1         poly         0.906788\n",
       "3         1      sigmoid         0.914002\n",
       "4         1          rbf         0.912856\n",
       "..      ...          ...              ...\n",
       "395      20      sigmoid         0.835381\n",
       "396      20          rbf         0.835381\n",
       "397      20       linear         0.926183\n",
       "398      20         poly         0.835381\n",
       "399      20      sigmoid         0.835381\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svc_grid[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f661d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9273875991771966\n",
      "{'C': 7, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(GSCV_SVC.best_score_)\n",
    "gscv_svc_acc = GSCV_SVC.best_score_\n",
    "print(GSCV_SVC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acafb862-706e-4bb3-b729-d1f2a406dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        25\n",
      "           1       1.00      0.38      0.55         8\n",
      "           2       0.98      0.98      0.98       133\n",
      "\n",
      "    accuracy                           0.95       166\n",
      "   macro avg       0.94      0.77      0.81       166\n",
      "weighted avg       0.96      0.95      0.95       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = GSCV_SVC.predict(x_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e74beb5-8a30-4ebc-a2ac-ee081bdfb318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.9560966459765983\n",
      "f1 Score  0.9463567583237272\n",
      "Recall  0.9518072289156626\n",
      "Specificity/TNR: 1.0\n",
      "Cohen Kappa: 0.8521981079577072\n",
      "AUC Score  0.9668371829462664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "cmSVC = confusion_matrix(y_test, GSCV_SVC.predict(x_test))\n",
    "\n",
    "#If we use TP TN FP and FN of below's comment we get range\n",
    "#FP = cmSVC.sum(axis=0) - np.diag(cmSVC)  \n",
    "#FN = cmSVC.sum(axis=1) - np.diag(cmSVC)\n",
    "#TP = np.diag(cmSVC)\n",
    "#TN = cmSVC.sum() - (FP + FN + TP)\n",
    "\n",
    "TP = cmSVC[1,1]  \n",
    "TN = cmSVC[0,0] \n",
    "FP = cmSVC[0,1] \n",
    "FN = cmSVC[1,0] \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/float(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/float(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/float(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/float(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/float(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/float(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/float(TP+FP)\n",
    "totalSVC=sum(sum(cmSVC))\n",
    "Accuracy = (TN+TP)/totalSVC\n",
    "# MCC\n",
    "val = (TP * TN) - (FP * FN)\n",
    "MCC_SVC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "\n",
    "\n",
    "y_pred_svc_grid = GSCV_SVC.predict(x_test)\n",
    "\n",
    "\n",
    "cohen_score = cohen_kappa_score(y_test, y_pred_svc_grid)\n",
    "f1 = f1_score(y_test, y_pred_svc_grid, average = \"weighted\")\n",
    "precision = precision_score(y_test, y_pred_svc_grid, average = \"weighted\")\n",
    "recall = recall_score(y_test, y_pred_svc_grid, average = \"weighted\")\n",
    "\n",
    "pred_prob = GSCV_SVC.predict_proba(x_test)\n",
    "auc_score = roc_auc_score(y_test, pred_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"Precision  {precision}\")\n",
    "print(f\"f1 Score  {f1}\")\n",
    "print(f\"Recall  {recall}\")\n",
    "specificity = TNR\n",
    "print(\"Specificity/TNR: \" + str(TNR))\n",
    "print(\"Cohen Kappa: \" + str(cohen_score))\n",
    "print(f\"AUC Score  {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "591d33c5-0e21-47da-82c7-d1f72e57dbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metrics': ['Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Cohen Kappa',\n",
       "  'AUC'],\n",
       " 'SVC': [0.9273875991771966,\n",
       "  0.9560966459765983,\n",
       "  0.9518072289156626,\n",
       "  0.9463567583237272,\n",
       "  0.8521981079577072,\n",
       "  0.9668371829462664]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_performances_grid = [gscv_svc_acc, precision, recall, f1, cohen_score, auc_score ]\n",
    "performance_dict_grid['SVC'] = svc_performances_grid\n",
    "\n",
    "performance_dict_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09450179",
   "metadata": {},
   "source": [
    "# Logistic Regression Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "453e610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.915\n",
      "Testing Accuracy: 0.916\n",
      "[[ 21   0   4]\n",
      " [  3   0   5]\n",
      " [  2   0 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82        25\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.94      0.98      0.96       133\n",
      "\n",
      "    accuracy                           0.92       166\n",
      "   macro avg       0.58      0.61      0.59       166\n",
      "weighted avg       0.87      0.92      0.89       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(x_train, y_train)\n",
    "\n",
    "y_pred_lr = modelLR.predict(x_test)\n",
    "lr_ac = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Training Accuracy: {:.3f}\".format(modelLR.score(x_train, y_train)))\n",
    "print(\"Testing Accuracy: {:.3f}\".format(modelLR.score(x_test, y_test)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "444dc4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.871339202965709\n",
      "f1 Score  0.8929473550309837\n",
      "Recall  0.9156626506024096\n",
      "Specificity/TNR: 1.0\n",
      "Cohen Kappa: 0.7195269128650736\n",
      "AUC Score  0.9547758351759231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\607833638.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  PPV = TP/float(TP+FP)\n",
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\607833638.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  FDR = FP/float(TP+FP)\n",
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\607833638.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  MCC_RFC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cmRFC = confusion_matrix(y_test, modelLR.predict(x_test))\n",
    "\n",
    "#If we use TP TN FP and FN of below's comment we get range\n",
    "#FP = cmSVC.sum(axis=0) - np.diag(cmSVC)  \n",
    "#FN = cmSVC.sum(axis=1) - np.diag(cmSVC)\n",
    "#TP = np.diag(cmSVC)\n",
    "#TN = cmSVC.sum() - (FP + FN + TP)\n",
    "\n",
    "TP = cmRFC[1,1]  \n",
    "TN = cmRFC[0,0] \n",
    "FP = cmRFC[0,1] \n",
    "FN = cmRFC[1,0] \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/float(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/float(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/float(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/float(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/float(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/float(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/float(TP+FP)\n",
    "# Accuracy\n",
    "totalRFC=sum(sum(cmRFC))\n",
    "Accuracy = (TN+TP)/totalRFC\n",
    "# MCC\n",
    "val = (TP * TN) - (FP * FN)\n",
    "MCC_RFC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "# Cohen Kappa\n",
    "Y_pred_lr = modelLR.predict(x_test)\n",
    "pred_prob = modelLR.predict_proba(x_test)\n",
    "\n",
    "\n",
    "cohen_score = cohen_kappa_score(y_test, Y_pred_lr)\n",
    "f1 = f1_score(y_test, Y_pred_lr, average = \"weighted\")\n",
    "precision = precision_score(y_test, Y_pred_lr, average = \"weighted\")\n",
    "recall = recall_score(y_test, Y_pred_lr, average = \"weighted\")\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"Precision  {precision}\")\n",
    "print(f\"f1 Score  {f1}\")\n",
    "print(f\"Recall  {recall}\")\n",
    "specificity = TNR\n",
    "print(\"Specificity/TNR: \" + str(TNR))\n",
    "\n",
    "print(\"Cohen Kappa: \" + str(cohen_score))\n",
    "print(f\"AUC Score  {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3343a87a-eba8-4e2f-bfa1-0c72ed222ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metrics': ['Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Cohen Kappa',\n",
       "  'AUC'],\n",
       " 'SVC': [0.9216867469879518,\n",
       "  0.8778053862131179,\n",
       "  0.9216867469879518,\n",
       "  0.8991815679005617,\n",
       "  0.7429116035263283,\n",
       "  0.9482794383636376],\n",
       " 'LR': [0.9156626506024096,\n",
       "  0.871339202965709,\n",
       "  0.9156626506024096,\n",
       "  0.8929473550309837,\n",
       "  0.7195269128650736,\n",
       "  0.9547758351759231]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_performances = [lr_ac, precision, recall, f1, cohen_score, auc_score ]\n",
    "performance_dict['LR'] = rfc_performances\n",
    "\n",
    "performance_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea7b46-ab8e-4869-83bf-3520fb43fa48",
   "metadata": {},
   "source": [
    "# Logistic Regression Hyperparameter Tuning GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f560703-69dc-4460-a4a6-613c47e7766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00787759, 0.01915295, 0.00378456, 0.00717876, 0.00797517,\n",
       "        0.02553213, 0.0043869 , 0.00728161, 0.00947635, 0.03650627,\n",
       "        0.00458593, 0.00956857, 0.01097119, 0.03649683, 0.00468614,\n",
       "        0.01276541, 0.01176622, 0.03710477, 0.00498428, 0.01685176,\n",
       "        0.01157351, 0.03666611, 0.00578368, 0.01924002, 0.01116924,\n",
       "        0.03191242, 0.00478597, 0.02114012, 0.0114646 , 0.03031785,\n",
       "        0.00478501, 0.02124286, 0.01136382, 0.02991881, 0.00478411,\n",
       "        0.02124467, 0.01116731, 0.0298167 , 0.00488586, 0.02124519]),\n",
       " 'std_fit_time': array([1.86355777e-03, 5.95779086e-03, 4.08881221e-04, 8.75105730e-04,\n",
       "        1.42302341e-05, 2.90507808e-03, 4.88228290e-04, 7.84060738e-04,\n",
       "        8.05888028e-04, 2.00474706e-03, 6.65296199e-04, 2.00675830e-03,\n",
       "        1.48678540e-03, 2.33100623e-03, 6.38624941e-04, 1.06711360e-03,\n",
       "        1.17168892e-03, 1.72378803e-03, 4.45698817e-04, 1.57901200e-03,\n",
       "        6.64383595e-04, 1.42653617e-03, 1.65560878e-03, 1.41524142e-03,\n",
       "        7.41347287e-04, 2.09673939e-03, 5.98256352e-04, 1.71489134e-03,\n",
       "        4.97391215e-04, 2.37007518e-03, 4.01459718e-04, 1.67062745e-03,\n",
       "        1.01430932e-03, 2.47531177e-03, 5.93888056e-04, 1.54568748e-03,\n",
       "        7.53046971e-04, 3.00212348e-03, 2.99040675e-04, 1.95309229e-03]),\n",
       " 'mean_score_time': array([0.00209503, 0.00149729, 0.00140378, 0.00149953, 0.00140226,\n",
       "        0.00159388, 0.00129762, 0.00139468, 0.00109782, 0.00178807,\n",
       "        0.00139923, 0.00149677, 0.00159242, 0.00199983, 0.00140021,\n",
       "        0.00159562, 0.00149817, 0.00159469, 0.00130177, 0.00159619,\n",
       "        0.00139668, 0.00179393, 0.00169764, 0.00170147, 0.00119975,\n",
       "        0.00149632, 0.00129814, 0.00129695, 0.00179985, 0.00149798,\n",
       "        0.00110013, 0.00129828, 0.00119967, 0.00169654, 0.00139687,\n",
       "        0.00169625, 0.00151489, 0.00150204, 0.0012974 , 0.00119829]),\n",
       " 'std_score_time': array([0.00144131, 0.00066891, 0.00049276, 0.00050229, 0.00066266,\n",
       "        0.00048639, 0.00063937, 0.00048581, 0.00029901, 0.00059559,\n",
       "        0.00048624, 0.00049865, 0.00048778, 0.00044646, 0.0004917 ,\n",
       "        0.00048753, 0.00050057, 0.0004781 , 0.00046119, 0.00048816,\n",
       "        0.0004885 , 0.0003911 , 0.00077937, 0.000637  , 0.00039666,\n",
       "        0.00049911, 0.00045663, 0.00046333, 0.00060163, 0.0004975 ,\n",
       "        0.00029825, 0.00045951, 0.00040328, 0.00063852, 0.00048825,\n",
       "        0.0004572 , 0.00048369, 0.00049849, 0.00045711, 0.0003987 ]),\n",
       " 'param_C': masked_array(data=[1.0, 1.0, 1.0, 1.0, 2.7825594022071245,\n",
       "                    2.7825594022071245, 2.7825594022071245,\n",
       "                    2.7825594022071245, 7.742636826811269,\n",
       "                    7.742636826811269, 7.742636826811269,\n",
       "                    7.742636826811269, 21.544346900318832,\n",
       "                    21.544346900318832, 21.544346900318832,\n",
       "                    21.544346900318832, 59.94842503189409,\n",
       "                    59.94842503189409, 59.94842503189409,\n",
       "                    59.94842503189409, 166.81005372000593,\n",
       "                    166.81005372000593, 166.81005372000593,\n",
       "                    166.81005372000593, 464.15888336127773,\n",
       "                    464.15888336127773, 464.15888336127773,\n",
       "                    464.15888336127773, 1291.5496650148827,\n",
       "                    1291.5496650148827, 1291.5496650148827,\n",
       "                    1291.5496650148827, 3593.813663804626,\n",
       "                    3593.813663804626, 3593.813663804626,\n",
       "                    3593.813663804626, 10000.0, 10000.0, 10000.0, 10000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2',\n",
       "                    'l1', 'l1', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga',\n",
       "                    'liblinear', 'saga', 'liblinear', 'saga', 'liblinear',\n",
       "                    'saga', 'liblinear', 'saga', 'liblinear', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 2.7825594022071245, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 2.7825594022071245, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 2.7825594022071245, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 2.7825594022071245, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 7.742636826811269, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 7.742636826811269, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 7.742636826811269, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 7.742636826811269, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 21.544346900318832, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 21.544346900318832, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 21.544346900318832, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 21.544346900318832, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 59.94842503189409, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 59.94842503189409, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 59.94842503189409, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 59.94842503189409, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 166.81005372000593, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 166.81005372000593, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 166.81005372000593, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 166.81005372000593, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 464.15888336127773, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 464.15888336127773, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 464.15888336127773, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 464.15888336127773, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1291.5496650148827, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1291.5496650148827, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1291.5496650148827, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1291.5496650148827, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 3593.813663804626, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 3593.813663804626, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 3593.813663804626, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 3593.813663804626, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10000.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10000.0, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 10000.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10000.0, 'penalty': 'l2', 'solver': 'saga'}],\n",
       " 'split0_test_score': array([0.90361446, 0.90361446, 0.91566265, 0.90361446, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265]),\n",
       " 'split1_test_score': array([0.92771084, 0.92771084, 0.93975904, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084]),\n",
       " 'split2_test_score': array([0.93975904, 0.91566265, 0.91566265, 0.91566265, 0.93975904,\n",
       "        0.92771084, 0.91566265, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.93975904, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.93975904, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084]),\n",
       " 'split3_test_score': array([0.90361446, 0.90361446, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.91566265, 0.90361446, 0.90361446,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265]),\n",
       " 'split4_test_score': array([0.89156627, 0.89156627, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.89156627, 0.89156627, 0.89156627, 0.90361446, 0.90361446,\n",
       "        0.89156627, 0.89156627, 0.91566265, 0.90361446, 0.89156627,\n",
       "        0.89156627, 0.91566265, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446]),\n",
       " 'split5_test_score': array([0.91566265, 0.91566265, 0.92771084, 0.92771084, 0.91566265,\n",
       "        0.90361446, 0.92771084, 0.92771084, 0.91566265, 0.90361446,\n",
       "        0.92771084, 0.91566265, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.91566265, 0.90361446]),\n",
       " 'split6_test_score': array([0.90243902, 0.90243902, 0.8902439 , 0.8902439 , 0.91463415,\n",
       "        0.92682927, 0.90243902, 0.90243902, 0.92682927, 0.92682927,\n",
       "        0.91463415, 0.91463415, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927]),\n",
       " 'split7_test_score': array([0.90243902, 0.8902439 , 0.91463415, 0.90243902, 0.8902439 ,\n",
       "        0.8902439 , 0.90243902, 0.90243902, 0.8902439 , 0.8902439 ,\n",
       "        0.90243902, 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.90243902, 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ]),\n",
       " 'split8_test_score': array([0.92682927, 0.91463415, 0.90243902, 0.91463415, 0.93902439,\n",
       "        0.92682927, 0.91463415, 0.93902439, 0.93902439, 0.92682927,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.92682927, 0.93902439,\n",
       "        0.92682927, 0.93902439, 0.92682927, 0.93902439, 0.92682927,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.92682927, 0.93902439,\n",
       "        0.92682927, 0.93902439, 0.92682927, 0.93902439, 0.92682927,\n",
       "        0.93902439, 0.92682927, 0.93902439, 0.92682927, 0.93902439,\n",
       "        0.92682927, 0.93902439, 0.92682927, 0.93902439, 0.92682927]),\n",
       " 'split9_test_score': array([0.92682927, 0.92682927, 0.93902439, 0.93902439, 0.92682927,\n",
       "        0.93902439, 0.93902439, 0.93902439, 0.91463415, 0.92682927,\n",
       "        0.93902439, 0.93902439, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.93902439, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927]),\n",
       " 'mean_test_score': array([0.91404643, 0.90919777, 0.91403174, 0.9116221 , 0.91526594,\n",
       "        0.91407582, 0.91284161, 0.91648545, 0.91526594, 0.91526594,\n",
       "        0.91770497, 0.91526594, 0.91769027, 0.91647076, 0.91528063,\n",
       "        0.91650015, 0.91769027, 0.91647076, 0.91528063, 0.91526594,\n",
       "        0.91769027, 0.91647076, 0.91769027, 0.91647076, 0.91769027,\n",
       "        0.91647076, 0.91769027, 0.91647076, 0.91769027, 0.91647076,\n",
       "        0.91769027, 0.91647076, 0.91769027, 0.91647076, 0.91769027,\n",
       "        0.91647076, 0.91769027, 0.91647076, 0.91769027, 0.91647076]),\n",
       " 'std_test_score': array([0.01473004, 0.01242937, 0.01671166, 0.01538121, 0.01706695,\n",
       "        0.01650006, 0.01406501, 0.01655576, 0.01428935, 0.01320763,\n",
       "        0.01591284, 0.01706695, 0.01407407, 0.01262655, 0.01612787,\n",
       "        0.01644663, 0.01407407, 0.01262655, 0.01612787, 0.01320763,\n",
       "        0.01407407, 0.01262655, 0.01407407, 0.01262655, 0.01407407,\n",
       "        0.01262655, 0.01407407, 0.01262655, 0.01407407, 0.01262655,\n",
       "        0.01407407, 0.01262655, 0.01407407, 0.01262655, 0.01407407,\n",
       "        0.01262655, 0.01407407, 0.01262655, 0.01407407, 0.01262655]),\n",
       " 'rank_test_score': array([36, 40, 37, 39, 30, 35, 38, 15, 34, 30,  1, 30,  2, 16, 28, 14,  2,\n",
       "        16, 28, 30,  2, 16,  2, 16,  2, 16,  2, 16,  2, 16,  2, 16,  2, 16,\n",
       "         2, 16,  2, 16,  2, 16])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "C = np.logspace(0, 4, 10)\n",
    "penalty = ['l1', 'l2']\n",
    "solver = ['liblinear', 'saga']\n",
    "hyperparameters = dict(C=C, penalty=penalty, solver=solver)\n",
    "logistic = linear_model.LogisticRegression()\n",
    "GSCV_LR = GridSearchCV(logistic, hyperparameters, cv = 10)\n",
    "GSCV_LR.fit(X, Y)\n",
    "GSCV_LR.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40aef693-3a1d-4318-83e3-9482a5260994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072907</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.912856</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.915251</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049671</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.906788</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059637</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914002</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085865</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.912856</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.073699</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 20, 'gamma': 0.001, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.047079</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'linear'}</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.926183</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'poly'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 20, 'gamma': 0.0001, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0         0.072907      0.009937         0.003788        0.000398       1   \n",
       "1         0.041394      0.003462         0.002288        0.000456       1   \n",
       "2         0.049671      0.002594         0.002391        0.000481       1   \n",
       "3         0.059637      0.003642         0.002497        0.000501       1   \n",
       "4         0.085865      0.007816         0.004191        0.000598       1   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "395       0.073699      0.007601         0.002893        0.000300      20   \n",
       "396       0.187797      0.008309         0.004588        0.001277      20   \n",
       "397       0.047079      0.002033         0.001994        0.000444      20   \n",
       "398       0.036304      0.000481         0.002293        0.000454      20   \n",
       "399       0.057743      0.001808         0.002297        0.000455      20   \n",
       "\n",
       "    param_gamma param_kernel                                           params  \\\n",
       "0             1          rbf            {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "1             1       linear         {'C': 1, 'gamma': 1, 'kernel': 'linear'}   \n",
       "2             1         poly           {'C': 1, 'gamma': 1, 'kernel': 'poly'}   \n",
       "3             1      sigmoid        {'C': 1, 'gamma': 1, 'kernel': 'sigmoid'}   \n",
       "4           0.1          rbf          {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "..          ...          ...                                              ...   \n",
       "395       0.001      sigmoid   {'C': 20, 'gamma': 0.001, 'kernel': 'sigmoid'}   \n",
       "396      0.0001          rbf      {'C': 20, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "397      0.0001       linear   {'C': 20, 'gamma': 0.0001, 'kernel': 'linear'}   \n",
       "398      0.0001         poly     {'C': 20, 'gamma': 0.0001, 'kernel': 'poly'}   \n",
       "399      0.0001      sigmoid  {'C': 20, 'gamma': 0.0001, 'kernel': 'sigmoid'}   \n",
       "\n",
       "     split0_test_score  split1_test_score  ...  split3_test_score  \\\n",
       "0             0.903614           0.927711  ...           0.903614   \n",
       "1             0.915663           0.927711  ...           0.903614   \n",
       "2             0.915663           0.891566  ...           0.903614   \n",
       "3             0.915663           0.939759  ...           0.903614   \n",
       "4             0.927711           0.891566  ...           0.915663   \n",
       "..                 ...                ...  ...                ...   \n",
       "395           0.831325           0.831325  ...           0.831325   \n",
       "396           0.831325           0.831325  ...           0.831325   \n",
       "397           0.915663           0.927711  ...           0.903614   \n",
       "398           0.831325           0.831325  ...           0.831325   \n",
       "399           0.831325           0.831325  ...           0.831325   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0             0.903614           0.915663           0.914634   \n",
       "1             0.903614           0.927711           0.902439   \n",
       "2             0.903614           0.903614           0.902439   \n",
       "3             0.903614           0.939759           0.902439   \n",
       "4             0.903614           0.915663           0.914634   \n",
       "..                 ...                ...                ...   \n",
       "395           0.831325           0.831325           0.841463   \n",
       "396           0.831325           0.831325           0.841463   \n",
       "397           0.915663           0.927711           0.926829   \n",
       "398           0.831325           0.831325           0.841463   \n",
       "399           0.831325           0.831325           0.841463   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0             0.914634           0.914634           0.926829         0.912856   \n",
       "1             0.914634           0.914634           0.926829         0.915251   \n",
       "2             0.914634           0.902439           0.914634         0.906788   \n",
       "3             0.902439           0.914634           0.902439         0.914002   \n",
       "4             0.926829           0.902439           0.926829         0.912856   \n",
       "..                 ...                ...                ...              ...   \n",
       "395           0.841463           0.841463           0.841463         0.835381   \n",
       "396           0.841463           0.841463           0.841463         0.835381   \n",
       "397           0.939024           0.926829           0.939024         0.926183   \n",
       "398           0.841463           0.841463           0.841463         0.835381   \n",
       "399           0.841463           0.841463           0.841463         0.835381   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "0          0.008803              161  \n",
       "1          0.009384              136  \n",
       "2          0.007618              184  \n",
       "3          0.013963              160  \n",
       "4          0.011673              161  \n",
       "..              ...              ...  \n",
       "395        0.004967              228  \n",
       "396        0.004967              228  \n",
       "397        0.011182               17  \n",
       "398        0.004967              228  \n",
       "399        0.004967              228  \n",
       "\n",
       "[400 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_grid = pd.DataFrame(GSCV_SVC.cv_results_)\n",
    "df_lr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e7c99fb-b81c-4b24-af36-99389fe10eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.912856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.915251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.906788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.914002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.912856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>20</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.926183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>20</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>20</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.835381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C param_kernel  mean_test_score\n",
       "0         1          rbf         0.912856\n",
       "1         1       linear         0.915251\n",
       "2         1         poly         0.906788\n",
       "3         1      sigmoid         0.914002\n",
       "4         1          rbf         0.912856\n",
       "..      ...          ...              ...\n",
       "395      20      sigmoid         0.835381\n",
       "396      20          rbf         0.835381\n",
       "397      20       linear         0.926183\n",
       "398      20         poly         0.835381\n",
       "399      20      sigmoid         0.835381\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_grid[['param_C', 'param_kernel', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4e8b67e-d755-46a6-ab60-cd54a11997a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9177049662062886\n",
      "{'C': 7.742636826811269, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(GSCV_LR.best_score_)\n",
    "gscv_lr_acc = GSCV_LR.best_score_\n",
    "print(GSCV_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7defc638-b02d-4b0b-8d92-fa1c7f30c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        25\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.95      0.98      0.97       133\n",
      "\n",
      "    accuracy                           0.93       166\n",
      "   macro avg       0.59      0.63      0.61       166\n",
      "weighted avg       0.88      0.93      0.91       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = GSCV_LR.predict(x_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "324001d6-ca23-4eae-852c-d63d309fcb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.8842731173139764\n",
      "f1 Score  0.905308066492804\n",
      "Recall  0.927710843373494\n",
      "Specificity/TNR: 1.0\n",
      "Cohen Kappa: 0.7657021877205363\n",
      "AUC Score  0.9547160766769326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\4076961341.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  PPV = TP/float(TP+FP)\n",
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\4076961341.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  FDR = FP/float(TP+FP)\n",
      "C:\\Users\\babar\\AppData\\Local\\Temp\\ipykernel_1092\\4076961341.py:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  MCC_RFC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
      "C:\\Users\\babar\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cmRFC = confusion_matrix(y_test, GSCV_LR.predict(x_test))\n",
    "\n",
    "#If we use TP TN FP and FN of below's comment we get range\n",
    "#FP = cmSVC.sum(axis=0) - np.diag(cmSVC)  \n",
    "#FN = cmSVC.sum(axis=1) - np.diag(cmSVC)\n",
    "#TP = np.diag(cmSVC)\n",
    "#TN = cmSVC.sum() - (FP + FN + TP)\n",
    "\n",
    "TP = cmRFC[1,1]  \n",
    "TN = cmRFC[0,0] \n",
    "FP = cmRFC[0,1] \n",
    "FN = cmRFC[1,0] \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/float(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/float(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/float(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/float(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/float(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/float(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/float(TP+FP)\n",
    "# Accuracy\n",
    "totalRFC=sum(sum(cmRFC))\n",
    "Accuracy = (TN+TP)/totalRFC\n",
    "# MCC\n",
    "val = (TP * TN) - (FP * FN)\n",
    "MCC_RFC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "# Cohen Kappa\n",
    "Y_pred_lr_grid = GSCV_LR.predict(x_test)\n",
    "pred_prob = GSCV_LR.predict_proba(x_test)\n",
    "\n",
    "\n",
    "cohen_score = cohen_kappa_score(y_test, Y_pred_lr_grid)\n",
    "f1 = f1_score(y_test, Y_pred_lr_grid, average = \"weighted\")\n",
    "precision = precision_score(y_test, Y_pred_lr_grid, average = \"weighted\")\n",
    "recall = recall_score(y_test, Y_pred_lr_grid, average = \"weighted\")\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"Precision  {precision}\")\n",
    "print(f\"f1 Score  {f1}\")\n",
    "print(f\"Recall  {recall}\")\n",
    "specificity = TNR\n",
    "print(\"Specificity/TNR: \" + str(TNR))\n",
    "\n",
    "print(\"Cohen Kappa: \" + str(cohen_score))\n",
    "print(f\"AUC Score  {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0896d737-2e23-43d5-b00f-e4263158448e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metrics': ['Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Cohen Kappa',\n",
       "  'AUC'],\n",
       " 'SVC': [0.9273875991771966,\n",
       "  0.9560966459765983,\n",
       "  0.9518072289156626,\n",
       "  0.9463567583237272,\n",
       "  0.8521981079577072,\n",
       "  0.9668371829462664],\n",
       " 'LR': [0.9177049662062886,\n",
       "  0.8842731173139764,\n",
       "  0.927710843373494,\n",
       "  0.905308066492804,\n",
       "  0.7657021877205363,\n",
       "  0.9547160766769326]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_performances_grid = [gscv_lr_acc, precision, recall, f1, cohen_score, auc_score ]\n",
    "performance_dict_grid['LR'] = lr_performances_grid\n",
    "\n",
    "performance_dict_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ac738",
   "metadata": {},
   "source": [
    "# KNN Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "108e96da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9096385542168675\n",
      "0.9096385542168675\n",
      "[[ 20   3   2]\n",
      " [  4   2   2]\n",
      " [  3   1 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77        25\n",
      "           1       0.33      0.25      0.29         8\n",
      "           2       0.97      0.97      0.97       133\n",
      "\n",
      "    accuracy                           0.91       166\n",
      "   macro avg       0.68      0.67      0.67       166\n",
      "weighted avg       0.90      0.91      0.91       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "modelKNN = KNeighborsClassifier() #, algorithm = 'ball_tree', weights = 'distance', metric = 'minkowski', p = 2\n",
    "modelKNN.fit(x_train, y_train)\n",
    "print(modelKNN.score(x_test, y_test))\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_knn = modelKNN.predict(x_test)\n",
    "ac = accuracy_score(y_test, y_pred_knn)\n",
    "print(accuracy_score(y_test, y_pred_knn))\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ea9a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.9047300312360553\n",
      "f1 Score  0.9067258043161657\n",
      "Recall  0.9096385542168675\n",
      "Specificity/TNR: 0.8695652173913043\n",
      "Cohen Kappa: 0.7276902887139107\n",
      "AUC Score  0.9171779331570854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cmKNN = confusion_matrix(y_test, modelKNN.predict(x_test))\n",
    "\n",
    "#If we use TP TN FP and FN of below's comment we get range\n",
    "#FP = cmSVC.sum(axis=0) - np.diag(cmSVC)  \n",
    "#FN = cmSVC.sum(axis=1) - np.diag(cmSVC)\n",
    "#TP = np.diag(cmSVC)\n",
    "#TN = cmSVC.sum() - (FP + FN + TP)\n",
    "\n",
    "TP = cmKNN[1,1]  \n",
    "TN = cmKNN[0,0] \n",
    "FP = cmKNN[0,1] \n",
    "FN = cmKNN[1,0] \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/float(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/float(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/float(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/float(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/float(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/float(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/float(TP+FP)\n",
    "# Accuracy\n",
    "totalKNN = sum(sum(cmKNN))\n",
    "Accuracy = (TN+TP)/totalKNN\n",
    "# MCC\n",
    "val = (TP * TN) - (FP * FN)\n",
    "MCC_KNN = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "# Cohen Kappa\n",
    "Y_pred_knn = modelKNN.predict(x_test)\n",
    "pred_prob = modelKNN.predict_proba(x_test)\n",
    "\n",
    "\n",
    "cohen_score = cohen_kappa_score(y_test, Y_pred_knn)\n",
    "f1 = f1_score(y_test, Y_pred_knn, average = \"weighted\")\n",
    "precision = precision_score(y_test, Y_pred_knn, average = \"weighted\")\n",
    "recall = recall_score(y_test, Y_pred_knn, average = \"weighted\")\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"Precision  {precision}\")\n",
    "print(f\"f1 Score  {f1}\")\n",
    "print(f\"Recall  {recall}\")\n",
    "specificity = TNR\n",
    "print(\"Specificity/TNR: \" + str(TNR))\n",
    "\n",
    "print(\"Cohen Kappa: \" + str(cohen_score))\n",
    "print(f\"AUC Score  {auc_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bc2b9ed-5250-477e-aaef-1068c2759ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metrics': ['Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Cohen Kappa',\n",
       "  'AUC'],\n",
       " 'SVC': [0.9216867469879518,\n",
       "  0.8778053862131179,\n",
       "  0.9216867469879518,\n",
       "  0.8991815679005617,\n",
       "  0.7429116035263283,\n",
       "  0.9482794383636376],\n",
       " 'LR': [0.9156626506024096,\n",
       "  0.871339202965709,\n",
       "  0.9156626506024096,\n",
       "  0.8929473550309837,\n",
       "  0.7195269128650736,\n",
       "  0.9547758351759231],\n",
       " 'KNN': [0.9096385542168675,\n",
       "  0.9047300312360553,\n",
       "  0.9096385542168675,\n",
       "  0.9067258043161657,\n",
       "  0.7276902887139107,\n",
       "  0.9171779331570854]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Specificity\", \"Cohen Kappa\", \"AUC\"]\n",
    "knn_performances = [ac, precision, recall, f1, cohen_score, auc_score ]\n",
    "performance_dict['KNN'] = knn_performances\n",
    "\n",
    "performance_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5b89f-cad2-4a32-9183-269a0cf482e6",
   "metadata": {},
   "source": [
    "# Logistic Regression Hyperparameter Tuning GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "093bdff8-0db6-48a0-967b-8f7009ceb5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00728083, 0.00548518, 0.00678089, 0.01047242, 0.00638227,\n",
       "        0.00618298, 0.00508554, 0.00558441, 0.00568435, 0.00568469,\n",
       "        0.00588419, 0.00688112, 0.00887558, 0.00857673, 0.00698111,\n",
       "        0.00488665, 0.00598383, 0.0053853 , 0.00518594, 0.00757968,\n",
       "        0.00628257, 0.00478628, 0.00558429, 0.00448823, 0.00458791,\n",
       "        0.00558875, 0.00508592, 0.00459154, 0.00777893, 0.00708055,\n",
       "        0.00588403, 0.00797842, 0.00628304, 0.01126995, 0.00608408,\n",
       "        0.00478692, 0.00598428, 0.00458708, 0.0057843 , 0.00478632,\n",
       "        0.00508595, 0.0051862 , 0.00508525, 0.00498607, 0.00528524,\n",
       "        0.00538509, 0.00498602, 0.00548482, 0.00448782, 0.00688131,\n",
       "        0.00528588, 0.00488639, 0.00548489, 0.00578425, 0.00558457,\n",
       "        0.00548484, 0.00548425, 0.00538588, 0.00747981, 0.00478623,\n",
       "        0.00737989, 0.00508637, 0.0081774 , 0.00478675, 0.00528529,\n",
       "        0.00508637, 0.00638366, 0.00588324, 0.0053848 , 0.00468674,\n",
       "        0.00977366, 0.00468693, 0.00458717, 0.00468693, 0.00518556,\n",
       "        0.00478685, 0.00598354, 0.00618305, 0.00558424, 0.00797744,\n",
       "        0.00718079, 0.00707948, 0.00448775, 0.00468638, 0.00448797,\n",
       "        0.0050859 , 0.00448732, 0.004687  , 0.00478709, 0.00448782,\n",
       "        0.00478628, 0.00498588, 0.00508566, 0.00498559, 0.00448825,\n",
       "        0.00508564, 0.00518575, 0.00458727, 0.00468707, 0.00498617,\n",
       "        0.00468693, 0.00508604, 0.00478628, 0.00548525, 0.00468698,\n",
       "        0.00498669, 0.00478685, 0.00508556, 0.00528529, 0.00478678,\n",
       "        0.00478654, 0.00468681, 0.00668128, 0.00877669, 0.00538492,\n",
       "        0.00508623, 0.00588377, 0.00538518, 0.00608387, 0.00797818]),\n",
       " 'std_fit_time': array([0.00214147, 0.00049822, 0.00308313, 0.00745341, 0.00337318,\n",
       "        0.00333183, 0.00069805, 0.00149301, 0.00244548, 0.00248504,\n",
       "        0.00338056, 0.00505542, 0.00657723, 0.00566277, 0.00504588,\n",
       "        0.00069857, 0.00267552, 0.00195478, 0.00171531, 0.0052047 ,\n",
       "        0.00330919, 0.00039901, 0.00142481, 0.00049896, 0.00066216,\n",
       "        0.00162104, 0.00137088, 0.00067047, 0.00658222, 0.00426478,\n",
       "        0.00137089, 0.00590083, 0.00282288, 0.01067687, 0.00310446,\n",
       "        0.00039855, 0.0026005 , 0.00048805, 0.00295201, 0.00059774,\n",
       "        0.00082815, 0.00132299, 0.00137067, 0.00063071, 0.00126549,\n",
       "        0.00162022, 0.00118019, 0.0015606 , 0.00050004, 0.00426472,\n",
       "        0.00045723, 0.00104184, 0.00286411, 0.0026687 , 0.00184986,\n",
       "        0.00190564, 0.00253313, 0.00195392, 0.00850042, 0.00097728,\n",
       "        0.0078688 , 0.00113256, 0.00876057, 0.00059816, 0.0012649 ,\n",
       "        0.00094062, 0.00432948, 0.00144171, 0.00119672, 0.00063853,\n",
       "        0.01009086, 0.0007787 , 0.00048886, 0.00045681, 0.0016567 ,\n",
       "        0.00039882, 0.00267621, 0.00298465, 0.00272018, 0.00693839,\n",
       "        0.00450074, 0.00511376, 0.00049892, 0.0004577 , 0.0006688 ,\n",
       "        0.00113244, 0.0004983 , 0.00063847, 0.00074651, 0.00049846,\n",
       "        0.00074658, 0.00089204, 0.00029955, 0.0008925 , 0.00049842,\n",
       "        0.00186318, 0.00146593, 0.00048855, 0.00063913, 0.00109212,\n",
       "        0.00118407, 0.00233712, 0.00040062, 0.00156127, 0.00063909,\n",
       "        0.00077257, 0.00086919, 0.00104185, 0.00141433, 0.00116328,\n",
       "        0.00097688, 0.0004572 , 0.00306022, 0.00577762, 0.00200465,\n",
       "        0.00053694, 0.00283575, 0.00091356, 0.0017531 , 0.00832019]),\n",
       " 'mean_score_time': array([0.01097019, 0.0068815 , 0.01166914, 0.00518627, 0.01256664,\n",
       "        0.00857732, 0.01306534, 0.00528612, 0.0119683 , 0.00588419,\n",
       "        0.0108711 , 0.00498686, 0.01366415, 0.00578494, 0.01555839,\n",
       "        0.00847688, 0.01296546, 0.01047175, 0.01376336, 0.00518587,\n",
       "        0.01236732, 0.00568573, 0.0097738 , 0.0075794 , 0.01276548,\n",
       "        0.00767539, 0.01097078, 0.00647922, 0.01755323, 0.01007328,\n",
       "        0.01815169, 0.00548558, 0.01745317, 0.00578432, 0.01057129,\n",
       "        0.00857732, 0.01146927, 0.0074806 , 0.01087112, 0.00608468,\n",
       "        0.01156962, 0.00438812, 0.00917621, 0.00488744, 0.01037276,\n",
       "        0.00688214, 0.01067178, 0.00498712, 0.00947411, 0.005286  ,\n",
       "        0.00977399, 0.00618391, 0.01027255, 0.00538566, 0.01276622,\n",
       "        0.00827775, 0.01436243, 0.00548539, 0.01027281, 0.00678232,\n",
       "        0.01047189, 0.00578465, 0.00967476, 0.00967426, 0.01306531,\n",
       "        0.007779  , 0.01017199, 0.00927577, 0.01166959, 0.00628388,\n",
       "        0.009375  , 0.00867758, 0.01087139, 0.00797923, 0.0133646 ,\n",
       "        0.00708125, 0.01326492, 0.00658302, 0.01296597, 0.00558505,\n",
       "        0.01037288, 0.00538628, 0.01087124, 0.00548656, 0.0094749 ,\n",
       "        0.00508664, 0.00987396, 0.00688226, 0.00987356, 0.00538547,\n",
       "        0.00927589, 0.00548635, 0.01027339, 0.00638382, 0.01436126,\n",
       "        0.00658302, 0.01206775, 0.00578458, 0.01067171, 0.00658245,\n",
       "        0.01336496, 0.00568495, 0.0102726 , 0.00528591, 0.00997362,\n",
       "        0.0056848 , 0.01256697, 0.00638344, 0.01137006, 0.00578499,\n",
       "        0.01136994, 0.00887661, 0.01226766, 0.00688162, 0.01126966,\n",
       "        0.00927556, 0.00967453, 0.00638332, 0.00967402, 0.00568457]),\n",
       " 'std_score_time': array([0.00227425, 0.00466535, 0.00356984, 0.00074563, 0.00729102,\n",
       "        0.006618  , 0.00756245, 0.00109706, 0.00401401, 0.00237897,\n",
       "        0.00237941, 0.00063128, 0.00470052, 0.00243464, 0.01126799,\n",
       "        0.00550329, 0.00591747, 0.00821438, 0.00866928, 0.00059882,\n",
       "        0.00546618, 0.00126583, 0.00171563, 0.00463935, 0.00760662,\n",
       "        0.00678035, 0.00351127, 0.0031943 , 0.007993  , 0.00571948,\n",
       "        0.00892979, 0.00049901, 0.01104589, 0.00097688, 0.00127627,\n",
       "        0.00823902, 0.00464021, 0.00237004, 0.0025014 , 0.00129584,\n",
       "        0.00535541, 0.00048899, 0.00230927, 0.00069879, 0.00306423,\n",
       "        0.00358041, 0.00342737, 0.00077248, 0.00162371, 0.00161151,\n",
       "        0.00277809, 0.00460981, 0.00260211, 0.00091385, 0.00463132,\n",
       "        0.00817678, 0.00970217, 0.00080407, 0.00199706, 0.0031151 ,\n",
       "        0.00257241, 0.00124537, 0.00154862, 0.00775121, 0.00707264,\n",
       "        0.00471681, 0.00171596, 0.00817613, 0.00333918, 0.00231936,\n",
       "        0.00048826, 0.00408915, 0.00335092, 0.0054987 , 0.00931518,\n",
       "        0.00280122, 0.00830891, 0.00205356, 0.0054991 , 0.00066223,\n",
       "        0.0042355 , 0.00173894, 0.00272931, 0.00200661, 0.00120092,\n",
       "        0.00053766, 0.00237896, 0.00602483, 0.00307228, 0.0006617 ,\n",
       "        0.0006387 , 0.00049939, 0.00223231, 0.00232643, 0.00619885,\n",
       "        0.00316041, 0.00559669, 0.0017733 , 0.00209474, 0.00232602,\n",
       "        0.00592046, 0.00089736, 0.00209478, 0.00045757, 0.00133856,\n",
       "        0.000639  , 0.00573281, 0.00184956, 0.00296614, 0.00097794,\n",
       "        0.00362853, 0.00633043, 0.00605073, 0.00346809, 0.00309174,\n",
       "        0.00596888, 0.0010021 , 0.0013524 , 0.00089745, 0.00063881]),\n",
       " 'param_metric': masked_array(data=['minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 1, 1, 2, 2, 3, 3, 4, 4,\n",
       "                    5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12,\n",
       "                    13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19,\n",
       "                    20, 20, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8,\n",
       "                    9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15,\n",
       "                    16, 16, 17, 17, 18, 18, 19, 19, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 14, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 14, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 18, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 18, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 20, 'weights': 'uniform'},\n",
       "  {'metric': 'minkowski', 'n_neighbors': 20, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 6, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 16, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 16, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 18, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 18, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'distance'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 20, 'weights': 'uniform'},\n",
       "  {'metric': 'euclidean', 'n_neighbors': 20, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 6, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 6, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 8, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 8, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 12, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 12, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 14, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 14, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 16, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 16, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 18, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 18, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'uniform'},\n",
       "  {'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.92771084, 0.92771084, 0.89156627, 0.92771084, 0.93975904,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.93975904, 0.90361446, 0.93975904, 0.91566265,\n",
       "        0.93975904, 0.91566265, 0.93975904, 0.91566265, 0.92771084,\n",
       "        0.91566265, 0.92771084, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.93975904, 0.90361446, 0.92771084, 0.89156627,\n",
       "        0.92771084, 0.89156627, 0.92771084, 0.89156627, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.89156627, 0.92771084, 0.93975904,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.93975904, 0.90361446, 0.93975904, 0.91566265,\n",
       "        0.93975904, 0.91566265, 0.93975904, 0.91566265, 0.92771084,\n",
       "        0.91566265, 0.92771084, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.93975904, 0.90361446, 0.92771084, 0.89156627,\n",
       "        0.92771084, 0.89156627, 0.92771084, 0.89156627, 0.92771084,\n",
       "        0.93975904, 0.93975904, 0.91566265, 0.93975904, 0.92771084,\n",
       "        0.92771084, 0.91566265, 0.91566265, 0.92771084, 0.92771084,\n",
       "        0.90361446, 0.91566265, 0.89156627, 0.92771084, 0.89156627,\n",
       "        0.91566265, 0.89156627, 0.91566265, 0.89156627, 0.92771084,\n",
       "        0.90361446, 0.91566265, 0.91566265, 0.91566265, 0.91566265,\n",
       "        0.92771084, 0.91566265, 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.91566265, 0.92771084, 0.90361446, 0.92771084, 0.90361446,\n",
       "        0.92771084, 0.90361446, 0.92771084, 0.90361446, 0.92771084]),\n",
       " 'split1_test_score': array([0.89156627, 0.89156627, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.91566265, 0.89156627, 0.91566265, 0.90361446, 0.93975904,\n",
       "        0.92771084, 0.93975904, 0.95180723, 0.95180723, 0.96385542,\n",
       "        0.95180723, 0.95180723, 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.92771084, 0.93975904, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.95180723, 0.92771084, 0.92771084,\n",
       "        0.91566265, 0.92771084, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.91566265, 0.91566265, 0.91566265, 0.91566265, 0.91566265,\n",
       "        0.89156627, 0.89156627, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.91566265, 0.89156627, 0.91566265, 0.90361446, 0.93975904,\n",
       "        0.92771084, 0.93975904, 0.95180723, 0.95180723, 0.96385542,\n",
       "        0.95180723, 0.95180723, 0.92771084, 0.92771084, 0.93975904,\n",
       "        0.92771084, 0.93975904, 0.92771084, 0.92771084, 0.92771084,\n",
       "        0.92771084, 0.92771084, 0.95180723, 0.92771084, 0.92771084,\n",
       "        0.91566265, 0.92771084, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.91566265, 0.91566265, 0.91566265, 0.91566265, 0.91566265,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.92771084, 0.90361446, 0.92771084,\n",
       "        0.90361446, 0.92771084, 0.93975904, 0.95180723, 0.91566265,\n",
       "        0.95180723, 0.92771084, 0.95180723, 0.91566265, 0.93975904,\n",
       "        0.92771084, 0.95180723, 0.92771084, 0.92771084, 0.90361446,\n",
       "        0.92771084, 0.91566265, 0.92771084, 0.91566265, 0.92771084,\n",
       "        0.93975904, 0.92771084, 0.91566265, 0.93975904, 0.93975904,\n",
       "        0.92771084, 0.92771084, 0.93975904, 0.92771084, 0.93975904]),\n",
       " 'split2_test_score': array([0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.90361446,\n",
       "        0.89156627, 0.90361446, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.87951807, 0.87951807, 0.84337349, 0.86746988, 0.86746988,\n",
       "        0.85542169, 0.86746988, 0.87951807, 0.86746988, 0.86746988,\n",
       "        0.87951807, 0.87951807, 0.89156627, 0.87951807, 0.89156627,\n",
       "        0.87951807, 0.90361446, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.90361446, 0.89156627, 0.90361446, 0.89156627, 0.87951807,\n",
       "        0.86746988, 0.87951807, 0.87951807, 0.89156627, 0.89156627,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.90361446,\n",
       "        0.89156627, 0.90361446, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.87951807, 0.87951807, 0.84337349, 0.86746988, 0.86746988,\n",
       "        0.85542169, 0.86746988, 0.87951807, 0.86746988, 0.86746988,\n",
       "        0.87951807, 0.87951807, 0.89156627, 0.87951807, 0.89156627,\n",
       "        0.87951807, 0.90361446, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.90361446, 0.89156627, 0.90361446, 0.89156627, 0.87951807,\n",
       "        0.86746988, 0.87951807, 0.87951807, 0.89156627, 0.89156627,\n",
       "        0.86746988, 0.86746988, 0.87951807, 0.86746988, 0.87951807,\n",
       "        0.86746988, 0.86746988, 0.86746988, 0.89156627, 0.87951807,\n",
       "        0.89156627, 0.87951807, 0.87951807, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.86746988, 0.86746988,\n",
       "        0.87951807, 0.87951807, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.90361446, 0.89156627, 0.89156627, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.89156627, 0.89156627, 0.87951807]),\n",
       " 'split3_test_score': array([0.87951807, 0.87951807, 0.90361446, 0.87951807, 0.89156627,\n",
       "        0.89156627, 0.91566265, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.92771084, 0.90361446,\n",
       "        0.89156627, 0.87951807, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.89156627, 0.89156627, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.89156627, 0.89156627, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.86746988, 0.86746988,\n",
       "        0.87951807, 0.87951807, 0.90361446, 0.87951807, 0.89156627,\n",
       "        0.89156627, 0.91566265, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.91566265, 0.91566265, 0.90361446, 0.92771084, 0.90361446,\n",
       "        0.89156627, 0.87951807, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.89156627, 0.89156627, 0.89156627, 0.87951807, 0.90361446,\n",
       "        0.89156627, 0.89156627, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.86746988, 0.86746988,\n",
       "        0.89156627, 0.89156627, 0.87951807, 0.89156627, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.86746988, 0.89156627,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.91566265, 0.91566265, 0.92771084, 0.91566265,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.90361446, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.90361446, 0.89156627, 0.89156627,\n",
       "        0.89156627, 0.89156627, 0.87951807, 0.87951807, 0.86746988,\n",
       "        0.86746988, 0.86746988, 0.86746988, 0.86746988, 0.86746988]),\n",
       " 'split4_test_score': array([0.91566265, 0.91566265, 0.87951807, 0.91566265, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.92771084, 0.90361446, 0.91566265,\n",
       "        0.86746988, 0.89156627, 0.87951807, 0.89156627, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.86746988, 0.89156627, 0.87951807, 0.89156627,\n",
       "        0.87951807, 0.89156627, 0.86746988, 0.89156627, 0.87951807,\n",
       "        0.89156627, 0.90361446, 0.90361446, 0.90361446, 0.87951807,\n",
       "        0.89156627, 0.89156627, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.91566265, 0.91566265, 0.87951807, 0.91566265, 0.90361446,\n",
       "        0.90361446, 0.90361446, 0.92771084, 0.90361446, 0.91566265,\n",
       "        0.86746988, 0.89156627, 0.87951807, 0.89156627, 0.87951807,\n",
       "        0.87951807, 0.87951807, 0.87951807, 0.87951807, 0.87951807,\n",
       "        0.87951807, 0.86746988, 0.89156627, 0.87951807, 0.89156627,\n",
       "        0.87951807, 0.89156627, 0.86746988, 0.89156627, 0.87951807,\n",
       "        0.89156627, 0.90361446, 0.90361446, 0.90361446, 0.87951807,\n",
       "        0.89156627, 0.89156627, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.91566265, 0.91566265, 0.87951807, 0.91566265, 0.86746988,\n",
       "        0.92771084, 0.89156627, 0.89156627, 0.89156627, 0.91566265,\n",
       "        0.87951807, 0.89156627, 0.86746988, 0.89156627, 0.87951807,\n",
       "        0.86746988, 0.89156627, 0.87951807, 0.89156627, 0.90361446,\n",
       "        0.90361446, 0.89156627, 0.89156627, 0.90361446, 0.89156627,\n",
       "        0.89156627, 0.90361446, 0.89156627, 0.89156627, 0.86746988,\n",
       "        0.89156627, 0.87951807, 0.89156627, 0.89156627, 0.89156627,\n",
       "        0.89156627, 0.89156627, 0.89156627, 0.89156627, 0.89156627]),\n",
       " 'split5_test_score': array([0.91566265, 0.91566265, 0.91566265, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.92771084, 0.89156627, 0.91566265,\n",
       "        0.89156627, 0.91566265, 0.89156627, 0.91566265, 0.89156627,\n",
       "        0.91566265, 0.89156627, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.92771084, 0.91566265,\n",
       "        0.92771084, 0.90361446, 0.92771084, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.93975904, 0.91566265, 0.92771084, 0.91566265,\n",
       "        0.93975904, 0.91566265, 0.92771084, 0.91566265, 0.91566265,\n",
       "        0.91566265, 0.91566265, 0.91566265, 0.91566265, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.92771084, 0.89156627, 0.91566265,\n",
       "        0.89156627, 0.91566265, 0.89156627, 0.91566265, 0.89156627,\n",
       "        0.91566265, 0.89156627, 0.90361446, 0.89156627, 0.90361446,\n",
       "        0.90361446, 0.91566265, 0.90361446, 0.92771084, 0.91566265,\n",
       "        0.92771084, 0.90361446, 0.92771084, 0.90361446, 0.91566265,\n",
       "        0.90361446, 0.93975904, 0.91566265, 0.92771084, 0.91566265,\n",
       "        0.93975904, 0.91566265, 0.92771084, 0.91566265, 0.91566265,\n",
       "        0.90361446, 0.90361446, 0.91566265, 0.90361446, 0.90361446,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.89156627, 0.90361446, 0.89156627, 0.90361446, 0.89156627,\n",
       "        0.91566265, 0.90361446, 0.91566265, 0.90361446, 0.91566265,\n",
       "        0.89156627, 0.91566265, 0.89156627, 0.91566265, 0.89156627,\n",
       "        0.91566265, 0.89156627, 0.91566265, 0.89156627, 0.91566265,\n",
       "        0.89156627, 0.91566265, 0.89156627, 0.91566265, 0.89156627,\n",
       "        0.91566265, 0.89156627, 0.91566265, 0.89156627, 0.90361446]),\n",
       " 'split6_test_score': array([0.82926829, 0.82926829, 0.85365854, 0.82926829, 0.90243902,\n",
       "        0.90243902, 0.87804878, 0.90243902, 0.8902439 , 0.91463415,\n",
       "        0.87804878, 0.8902439 , 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.82926829, 0.82926829, 0.85365854, 0.82926829, 0.90243902,\n",
       "        0.90243902, 0.87804878, 0.90243902, 0.8902439 , 0.91463415,\n",
       "        0.87804878, 0.8902439 , 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.85365854, 0.85365854, 0.85365854, 0.85365854, 0.90243902,\n",
       "        0.87804878, 0.86585366, 0.8902439 , 0.87804878, 0.8902439 ,\n",
       "        0.86585366, 0.87804878, 0.8902439 , 0.8902439 , 0.87804878,\n",
       "        0.90243902, 0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.8902439 , 0.90243902]),\n",
       " 'split7_test_score': array([0.87804878, 0.87804878, 0.87804878, 0.87804878, 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.90243902, 0.90243902, 0.8902439 ,\n",
       "        0.90243902, 0.91463415, 0.91463415, 0.91463415, 0.92682927,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.92682927, 0.91463415, 0.93902439, 0.92682927, 0.92682927,\n",
       "        0.91463415, 0.92682927, 0.91463415, 0.91463415, 0.91463415,\n",
       "        0.91463415, 0.90243902, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.91463415, 0.91463415,\n",
       "        0.87804878, 0.87804878, 0.87804878, 0.87804878, 0.8902439 ,\n",
       "        0.8902439 , 0.8902439 , 0.90243902, 0.90243902, 0.8902439 ,\n",
       "        0.90243902, 0.91463415, 0.91463415, 0.91463415, 0.92682927,\n",
       "        0.91463415, 0.92682927, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.92682927, 0.91463415, 0.93902439, 0.92682927, 0.92682927,\n",
       "        0.91463415, 0.92682927, 0.91463415, 0.91463415, 0.91463415,\n",
       "        0.91463415, 0.90243902, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.91463415, 0.91463415,\n",
       "        0.8902439 , 0.8902439 , 0.8902439 , 0.8902439 , 0.90243902,\n",
       "        0.8902439 , 0.8902439 , 0.91463415, 0.8902439 , 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.8902439 , 0.8902439 , 0.8902439 ,\n",
       "        0.90243902, 0.92682927, 0.90243902, 0.92682927, 0.91463415,\n",
       "        0.92682927, 0.91463415, 0.93902439, 0.91463415, 0.93902439,\n",
       "        0.92682927, 0.93902439, 0.91463415, 0.91463415, 0.90243902,\n",
       "        0.92682927, 0.8902439 , 0.8902439 , 0.8902439 , 0.90243902,\n",
       "        0.8902439 , 0.92682927, 0.90243902, 0.91463415, 0.90243902]),\n",
       " 'split8_test_score': array([0.8902439 , 0.8902439 , 0.87804878, 0.8902439 , 0.91463415,\n",
       "        0.91463415, 0.92682927, 0.91463415, 0.91463415, 0.91463415,\n",
       "        0.86585366, 0.90243902, 0.8902439 , 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.91463415, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.8902439 , 0.8902439 , 0.87804878, 0.8902439 , 0.91463415,\n",
       "        0.91463415, 0.92682927, 0.91463415, 0.91463415, 0.91463415,\n",
       "        0.86585366, 0.90243902, 0.8902439 , 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.91463415, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.91463415, 0.91463415, 0.90243902, 0.91463415, 0.91463415,\n",
       "        0.91463415, 0.91463415, 0.91463415, 0.91463415, 0.91463415,\n",
       "        0.8902439 , 0.91463415, 0.90243902, 0.91463415, 0.8902439 ,\n",
       "        0.92682927, 0.90243902, 0.92682927, 0.8902439 , 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415,\n",
       "        0.90243902, 0.91463415, 0.90243902, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.90243902, 0.91463415, 0.90243902, 0.91463415]),\n",
       " 'split9_test_score': array([0.90243902, 0.90243902, 0.87804878, 0.90243902, 0.87804878,\n",
       "        0.90243902, 0.8902439 , 0.90243902, 0.90243902, 0.8902439 ,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.8902439 ,\n",
       "        0.8902439 , 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.91463415, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.91463415, 0.92682927,\n",
       "        0.90243902, 0.90243902, 0.87804878, 0.90243902, 0.87804878,\n",
       "        0.90243902, 0.8902439 , 0.90243902, 0.90243902, 0.8902439 ,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.8902439 ,\n",
       "        0.8902439 , 0.90243902, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.90243902, 0.90243902, 0.90243902, 0.90243902, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.91463415, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.92682927, 0.92682927,\n",
       "        0.92682927, 0.92682927, 0.92682927, 0.91463415, 0.92682927,\n",
       "        0.87804878, 0.87804878, 0.87804878, 0.87804878, 0.90243902,\n",
       "        0.91463415, 0.91463415, 0.90243902, 0.90243902, 0.90243902,\n",
       "        0.91463415, 0.92682927, 0.92682927, 0.91463415, 0.90243902,\n",
       "        0.91463415, 0.91463415, 0.91463415, 0.8902439 , 0.90243902,\n",
       "        0.90243902, 0.8902439 , 0.90243902, 0.90243902, 0.91463415,\n",
       "        0.91463415, 0.92682927, 0.92682927, 0.90243902, 0.91463415,\n",
       "        0.91463415, 0.92682927, 0.91463415, 0.92682927, 0.91463415,\n",
       "        0.92682927, 0.91463415, 0.92682927, 0.92682927, 0.92682927]),\n",
       " 'mean_test_score': array([0.89096386, 0.89096386, 0.88612989, 0.89096386, 0.9031149 ,\n",
       "        0.90555392, 0.9031149 , 0.91159271, 0.90314428, 0.9103732 ,\n",
       "        0.8958419 , 0.90916838, 0.89832501, 0.91281222, 0.9043638 ,\n",
       "        0.90556862, 0.90196885, 0.9043638 , 0.90076403, 0.90437849,\n",
       "        0.90317367, 0.90558331, 0.90802233, 0.90680282, 0.91163679,\n",
       "        0.90922715, 0.91043197, 0.91163679, 0.90678813, 0.90922715,\n",
       "        0.90680282, 0.91282692, 0.90558331, 0.90922715, 0.89955921,\n",
       "        0.90680282, 0.90076403, 0.90800764, 0.90076403, 0.90802233,\n",
       "        0.89096386, 0.89096386, 0.88612989, 0.89096386, 0.9031149 ,\n",
       "        0.90555392, 0.9031149 , 0.91159271, 0.90314428, 0.9103732 ,\n",
       "        0.8958419 , 0.90916838, 0.89832501, 0.91281222, 0.9043638 ,\n",
       "        0.90556862, 0.90196885, 0.9043638 , 0.90076403, 0.90437849,\n",
       "        0.90317367, 0.90558331, 0.90802233, 0.90680282, 0.91163679,\n",
       "        0.90922715, 0.91043197, 0.91163679, 0.90678813, 0.90922715,\n",
       "        0.90680282, 0.91282692, 0.90558331, 0.90922715, 0.89955921,\n",
       "        0.90680282, 0.90076403, 0.90800764, 0.90076403, 0.90802233,\n",
       "        0.89703203, 0.89703203, 0.88978842, 0.89703203, 0.90074934,\n",
       "        0.90553923, 0.8970908 , 0.9043638 , 0.8970908 , 0.90797825,\n",
       "        0.89466647, 0.90558331, 0.89832501, 0.90796356, 0.89224214,\n",
       "        0.90921246, 0.90437849, 0.90919777, 0.89951513, 0.90918307,\n",
       "        0.90315898, 0.90675874, 0.90800764, 0.90919777, 0.90681751,\n",
       "        0.91284161, 0.90924185, 0.91163679, 0.90074934, 0.90437849,\n",
       "        0.905598  , 0.90558331, 0.89712019, 0.90678813, 0.89954452,\n",
       "        0.90437849, 0.90077872, 0.90800764, 0.90076403, 0.905598  ]),\n",
       " 'std_test_score': array([0.0263403 , 0.0263403 , 0.01688459, 0.0263403 , 0.01550576,\n",
       "        0.01194414, 0.01555163, 0.01233401, 0.01082456, 0.01570397,\n",
       "        0.02194715, 0.01903545, 0.02588532, 0.02281666, 0.02553665,\n",
       "        0.02684642, 0.02365704, 0.01820291, 0.01834394, 0.02039383,\n",
       "        0.01604168, 0.02066717, 0.01531352, 0.02011289, 0.01426109,\n",
       "        0.01875231, 0.01437853, 0.02284767, 0.01319719, 0.01626511,\n",
       "        0.01418822, 0.01932284, 0.01172716, 0.01534672, 0.01598752,\n",
       "        0.02150795, 0.01484497, 0.01714009, 0.01482095, 0.0170629 ,\n",
       "        0.0263403 , 0.0263403 , 0.01688459, 0.0263403 , 0.01550576,\n",
       "        0.01194414, 0.01555163, 0.01233401, 0.01082456, 0.01570397,\n",
       "        0.02194715, 0.01903545, 0.02588532, 0.02281666, 0.02553665,\n",
       "        0.02684642, 0.02365704, 0.01820291, 0.01834394, 0.02039383,\n",
       "        0.01604168, 0.02066717, 0.01531352, 0.02011289, 0.01426109,\n",
       "        0.01875231, 0.01437853, 0.02284767, 0.01319719, 0.01626511,\n",
       "        0.01418822, 0.01932284, 0.01172716, 0.01534672, 0.01598752,\n",
       "        0.02150795, 0.01484497, 0.01714009, 0.01482095, 0.0170629 ,\n",
       "        0.02462612, 0.02462612, 0.01857413, 0.02462612, 0.01584674,\n",
       "        0.01948388, 0.01737436, 0.01655279, 0.01645295, 0.0155241 ,\n",
       "        0.01340803, 0.01687668, 0.02025311, 0.02045824, 0.01147162,\n",
       "        0.02234913, 0.01559303, 0.02109045, 0.01797148, 0.01896507,\n",
       "        0.01422961, 0.01959643, 0.01442609, 0.00974684, 0.0130803 ,\n",
       "        0.01176164, 0.01435101, 0.01317705, 0.01161861, 0.01891679,\n",
       "        0.01758261, 0.01847867, 0.01215714, 0.02019517, 0.01855734,\n",
       "        0.02042874, 0.01827767, 0.02024623, 0.01755508, 0.02131448]),\n",
       " 'rank_test_score': array([112, 112, 119, 112,  79,  61,  79,  11,  77,  15, 108,  28,  99,\n",
       "          4,  69,  59,  83,  71,  89,  64,  74,  53,  30,  43,   6,  18,\n",
       "         13,   8,  47,  18,  41,   2,  53,  18,  95,  43,  86,  34,  89,\n",
       "         30, 112, 112, 119, 112,  79,  61,  79,  11,  77,  15, 108,  28,\n",
       "         99,   4,  69,  59,  83,  71,  89,  64,  74,  53,  30,  43,   6,\n",
       "         18,  13,   8,  47,  18,  41,   2,  53,  18,  95,  43,  86,  34,\n",
       "         89,  30, 105, 105, 118, 105,  93,  63, 103,  71, 103,  38, 110,\n",
       "         53,  99,  39, 111,  24,  64,  25,  98,  27,  76,  50,  34,  25,\n",
       "         40,   1,  17,   8,  93,  68,  51,  53, 102,  47,  97,  64,  85,\n",
       "         34,  86,  51])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = { 'n_neighbors' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "\n",
    "GSCV_KNN = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv = 10, n_jobs = -1)\n",
    "GSCV_KNN.fit(X, Y)\n",
    "GSCV_KNN.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "156f21b6-5b36-492d-aba8-9e1900d76a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.890964</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 1, 'wei...</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.890964</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 2, 'wei...</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 2, 'wei...</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.890964</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>minkowski</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'minkowski', 'n_neighbors': 3, 'wei...</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.903115</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>18</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 18, 'we...</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.904378</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>19</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 19, 'we...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.900779</td>\n",
       "      <td>0.018278</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 19, 'we...</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.908008</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.009674</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>20</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 20, 'we...</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.900764</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>20</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 20, 'we...</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.905598</td>\n",
       "      <td>0.021314</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.007281      0.002141         0.010970        0.002274   \n",
       "1         0.005485      0.000498         0.006881        0.004665   \n",
       "2         0.006781      0.003083         0.011669        0.003570   \n",
       "3         0.010472      0.007453         0.005186        0.000746   \n",
       "4         0.006382      0.003373         0.012567        0.007291   \n",
       "..             ...           ...              ...             ...   \n",
       "115       0.005086      0.000537         0.009276        0.005969   \n",
       "116       0.005884      0.002836         0.009675        0.001002   \n",
       "117       0.005385      0.000914         0.006383        0.001352   \n",
       "118       0.006084      0.001753         0.009674        0.000897   \n",
       "119       0.007978      0.008320         0.005685        0.000639   \n",
       "\n",
       "    param_metric param_n_neighbors param_weights  \\\n",
       "0      minkowski                 1       uniform   \n",
       "1      minkowski                 1      distance   \n",
       "2      minkowski                 2       uniform   \n",
       "3      minkowski                 2      distance   \n",
       "4      minkowski                 3       uniform   \n",
       "..           ...               ...           ...   \n",
       "115    manhattan                18      distance   \n",
       "116    manhattan                19       uniform   \n",
       "117    manhattan                19      distance   \n",
       "118    manhattan                20       uniform   \n",
       "119    manhattan                20      distance   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'metric': 'minkowski', 'n_neighbors': 1, 'wei...           0.927711   \n",
       "1    {'metric': 'minkowski', 'n_neighbors': 1, 'wei...           0.927711   \n",
       "2    {'metric': 'minkowski', 'n_neighbors': 2, 'wei...           0.891566   \n",
       "3    {'metric': 'minkowski', 'n_neighbors': 2, 'wei...           0.927711   \n",
       "4    {'metric': 'minkowski', 'n_neighbors': 3, 'wei...           0.939759   \n",
       "..                                                 ...                ...   \n",
       "115  {'metric': 'manhattan', 'n_neighbors': 18, 'we...           0.927711   \n",
       "116  {'metric': 'manhattan', 'n_neighbors': 19, 'we...           0.903614   \n",
       "117  {'metric': 'manhattan', 'n_neighbors': 19, 'we...           0.927711   \n",
       "118  {'metric': 'manhattan', 'n_neighbors': 20, 'we...           0.903614   \n",
       "119  {'metric': 'manhattan', 'n_neighbors': 20, 'we...           0.927711   \n",
       "\n",
       "     split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0             0.891566  ...           0.879518           0.915663   \n",
       "1             0.891566  ...           0.879518           0.915663   \n",
       "2             0.903614  ...           0.903614           0.879518   \n",
       "3             0.891566  ...           0.879518           0.915663   \n",
       "4             0.903614  ...           0.891566           0.903614   \n",
       "..                 ...  ...                ...                ...   \n",
       "115           0.927711  ...           0.867470           0.891566   \n",
       "116           0.927711  ...           0.867470           0.891566   \n",
       "117           0.939759  ...           0.867470           0.891566   \n",
       "118           0.927711  ...           0.867470           0.891566   \n",
       "119           0.939759  ...           0.867470           0.891566   \n",
       "\n",
       "     split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0             0.915663           0.829268           0.878049   \n",
       "1             0.915663           0.829268           0.878049   \n",
       "2             0.915663           0.853659           0.878049   \n",
       "3             0.915663           0.829268           0.878049   \n",
       "4             0.903614           0.902439           0.890244   \n",
       "..                 ...                ...                ...   \n",
       "115           0.915663           0.902439           0.890244   \n",
       "116           0.891566           0.902439           0.926829   \n",
       "117           0.915663           0.902439           0.902439   \n",
       "118           0.891566           0.890244           0.914634   \n",
       "119           0.903614           0.902439           0.902439   \n",
       "\n",
       "     split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.890244           0.902439         0.890964        0.026340   \n",
       "1             0.890244           0.902439         0.890964        0.026340   \n",
       "2             0.878049           0.878049         0.886130        0.016885   \n",
       "3             0.890244           0.902439         0.890964        0.026340   \n",
       "4             0.914634           0.878049         0.903115        0.015506   \n",
       "..                 ...                ...              ...             ...   \n",
       "115           0.914634           0.926829         0.904378        0.020429   \n",
       "116           0.902439           0.914634         0.900779        0.018278   \n",
       "117           0.914634           0.926829         0.908008        0.020246   \n",
       "118           0.902439           0.926829         0.900764        0.017555   \n",
       "119           0.914634           0.926829         0.905598        0.021314   \n",
       "\n",
       "     rank_test_score  \n",
       "0                112  \n",
       "1                112  \n",
       "2                119  \n",
       "3                112  \n",
       "4                 79  \n",
       "..               ...  \n",
       "115               64  \n",
       "116               85  \n",
       "117               34  \n",
       "118               86  \n",
       "119               51  \n",
       "\n",
       "[120 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_grid = pd.DataFrame(GSCV_KNN.cv_results_)\n",
    "df_lr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3ed3fea-8f10-455e-a0fa-ce2be54d89b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>2</td>\n",
       "      <td>0.886130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>2</td>\n",
       "      <td>0.890964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>18</td>\n",
       "      <td>0.904378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>19</td>\n",
       "      <td>0.900779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>19</td>\n",
       "      <td>0.908008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>20</td>\n",
       "      <td>0.900764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>20</td>\n",
       "      <td>0.905598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_metric param_n_neighbors  mean_test_score\n",
       "0      minkowski                 1         0.890964\n",
       "1      minkowski                 1         0.890964\n",
       "2      minkowski                 2         0.886130\n",
       "3      minkowski                 2         0.890964\n",
       "4      minkowski                 3         0.903115\n",
       "..           ...               ...              ...\n",
       "115    manhattan                18         0.904378\n",
       "116    manhattan                19         0.900779\n",
       "117    manhattan                19         0.908008\n",
       "118    manhattan                20         0.900764\n",
       "119    manhattan                20         0.905598\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_grid[['param_metric', 'param_n_neighbors', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd2dc809-851d-44ad-b4c2-607664d3599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128416103438143\n",
      "{'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(GSCV_KNN.best_score_)\n",
    "gscv_knn_acc = GSCV_KNN.best_score_\n",
    "print(GSCV_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03d95b7e-9582-425d-9a9e-08471ad3c99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00       133\n",
      "\n",
      "    accuracy                           1.00       166\n",
      "   macro avg       1.00      1.00      1.00       166\n",
      "weighted avg       1.00      1.00      1.00       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = GSCV_KNN.predict(x_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7afb7ffd-4e21-45fc-806a-9127bd5e72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  1.0\n",
      "f1 Score  1.0\n",
      "Recall  1.0\n",
      "Specificity/TNR: 1.0\n",
      "Cohen Kappa: 1.0\n",
      "AUC Score  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cmRFC = confusion_matrix(y_test, GSCV_KNN.predict(x_test))\n",
    "\n",
    "#If we use TP TN FP and FN of below's comment we get range\n",
    "#FP = cmSVC.sum(axis=0) - np.diag(cmSVC)  \n",
    "#FN = cmSVC.sum(axis=1) - np.diag(cmSVC)\n",
    "#TP = np.diag(cmSVC)\n",
    "#TN = cmSVC.sum() - (FP + FN + TP)\n",
    "\n",
    "TP = cmRFC[1,1]  \n",
    "TN = cmRFC[0,0] \n",
    "FP = cmRFC[0,1] \n",
    "FN = cmRFC[1,0] \n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/float(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/float(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/float(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/float(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/float(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/float(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/float(TP+FP)\n",
    "# Accuracy\n",
    "totalRFC=sum(sum(cmRFC))\n",
    "Accuracy = (TN+TP)/totalRFC\n",
    "# MCC\n",
    "val = (TP * TN) - (FP * FN)\n",
    "MCC_RFC = val / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "# Cohen Kappa\n",
    "Y_pred_knn_grid = GSCV_KNN.predict(x_test)\n",
    "pred_prob = GSCV_KNN.predict_proba(x_test)\n",
    "\n",
    "\n",
    "cohen_score = cohen_kappa_score(y_test, Y_pred_knn_grid)\n",
    "f1 = f1_score(y_test, Y_pred_knn_grid, average = \"weighted\")\n",
    "precision = precision_score(y_test, Y_pred_knn_grid, average = \"weighted\")\n",
    "recall = recall_score(y_test, Y_pred_knn_grid, average = \"weighted\")\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"Precision  {precision}\")\n",
    "print(f\"f1 Score  {f1}\")\n",
    "print(f\"Recall  {recall}\")\n",
    "specificity = TNR\n",
    "print(\"Specificity/TNR: \" + str(TNR))\n",
    "\n",
    "print(\"Cohen Kappa: \" + str(cohen_score))\n",
    "print(f\"AUC Score  {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a10820c9-ce45-454a-8eb5-36cc71357813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metrics': ['Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Cohen Kappa',\n",
       "  'AUC'],\n",
       " 'SVC': [0.9273875991771966,\n",
       "  0.9560966459765983,\n",
       "  0.9518072289156626,\n",
       "  0.9463567583237272,\n",
       "  0.8521981079577072,\n",
       "  0.9668371829462664],\n",
       " 'LR': [0.9177049662062886,\n",
       "  0.8842731173139764,\n",
       "  0.927710843373494,\n",
       "  0.905308066492804,\n",
       "  0.7657021877205363,\n",
       "  0.9547160766769326],\n",
       " 'KNN': [0.9128416103438143, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_performances_grid = [gscv_knn_acc, precision, recall, f1, cohen_score, auc_score ]\n",
    "performance_dict_grid['KNN'] = knn_performances_grid\n",
    "\n",
    "performance_dict_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62010254-c26d-4768-986e-ed0262dcabf0",
   "metadata": {},
   "source": [
    "# Before Normalization"
   ]
  },
  {
   "attachments": {
    "Before-normalization-all-classifier-accuracy.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c40dbd9a",
   "metadata": {},
   "source": [
    "![Before-normalization-all-classifier-accuracy.PNG](attachment:Before-normalization-all-classifier-accuracy.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e686eeb-6243-4712-8e6c-8d8426fbbc8c",
   "metadata": {},
   "source": [
    "# Result of all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad1068eb-215a-44ee-815b-130278eba26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.909639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.871339</td>\n",
       "      <td>0.904730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.909639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.899182</td>\n",
       "      <td>0.892947</td>\n",
       "      <td>0.906726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cohen Kappa</td>\n",
       "      <td>0.742912</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.727690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.948279</td>\n",
       "      <td>0.954776</td>\n",
       "      <td>0.917178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metrics       SVC        LR       KNN\n",
       "0     Accuracy  0.921687  0.915663  0.909639\n",
       "1    Precision  0.877805  0.871339  0.904730\n",
       "2       Recall  0.921687  0.915663  0.909639\n",
       "3     F1 Score  0.899182  0.892947  0.906726\n",
       "4  Cohen Kappa  0.742912  0.719527  0.727690\n",
       "5          AUC  0.948279  0.954776  0.917178"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame.from_dict(performance_dict)\n",
    "performance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44682791-8087-489d-b01a-11bf94295d7e",
   "metadata": {},
   "source": [
    "# Result of all classifiers after hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55b916cc-74ae-4660-9bd7-29dd914241e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.927388</td>\n",
       "      <td>0.917705</td>\n",
       "      <td>0.912842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.956097</td>\n",
       "      <td>0.884273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.951807</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.946357</td>\n",
       "      <td>0.905308</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cohen Kappa</td>\n",
       "      <td>0.852198</td>\n",
       "      <td>0.765702</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metrics       SVC        LR       KNN\n",
       "0     Accuracy  0.927388  0.917705  0.912842\n",
       "1    Precision  0.956097  0.884273  1.000000\n",
       "2       Recall  0.951807  0.927711  1.000000\n",
       "3     F1 Score  0.946357  0.905308  1.000000\n",
       "4  Cohen Kappa  0.852198  0.765702  1.000000\n",
       "5          AUC  0.966837  0.954716  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df_grid = pd.DataFrame.from_dict(performance_dict_grid)\n",
    "performance_df_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe3732",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "976ca9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# predict probabilities\n",
    "pred_prob1 = modelSVC.predict_proba(x_test)\n",
    "pred_prob5 = modelLR.predict_proba(x_test)\n",
    "pred_prob7 = modelKNN.predict_proba(x_test)\n",
    "\n",
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label = 1)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label = 1)\n",
    "fpr7, tpr7, thresh7 = roc_curve(y_test, pred_prob7[:,1], pos_label = 1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbc040b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "sb.set_theme(style = 'whitegrid')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr1, tpr1, linestyle = '--', color = 'magenta', label = 'SVM')\n",
    "plt.plot(fpr7, tpr7, linestyle = '--', color = 'cyan', label = 'KNN')\n",
    "plt.plot(fpr5, tpr5, linestyle = '--', color = 'darkorange', label = 'LR')\n",
    "plt.plot(p_fpr, p_tpr, linestyle = '--', color = 'cornflowerblue')\n",
    "# title\n",
    "plt.title('Dimentionality Reduction with PCA')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "# plt.savefig(\"Dimentionality Reduction with PCA.png\", dpi=300)\n",
    "\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
